{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # LangChain åº”ç”¨å¼€å‘æŒ‡å—ï¼ˆè¿›é˜¶ï¼‰: ä½¿ç”¨æ¡ˆä¾‹ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*æœ¬æ–‡æ¡£åŸºäº[LangChain æ¦‚å¿µæ–‡æ¡£](https://docs.langchain.com/docs/)*\n",
    "\n",
    "**ç›®æ ‡ï¼š**\n",
    "\n",
    "1. æ¿€åŠ±æ‚¨å»æ„å»º\n",
    "2. é€šè¿‡[ELI5](https://www.dictionary.com/e/slang/eli5/#:~:text=ELI5%20is%20short%20for%20%E2%80%9CExplain,a%20complicated%20question%20or%20problem.)ç¤ºä¾‹å’Œä»£ç ç‰‡æ®µï¼Œæä¾›LangChainä¸»è¦ç”¨ä¾‹çš„åˆæ­¥ç†è§£ã€‚è¦äº†è§£LangChainçš„*åŸºç¡€çŸ¥è¯†*ï¼Œè¯·æŸ¥çœ‹æ–‡æ¡£ç¬¬1éƒ¨åˆ†ï¼šåŸºç¡€çŸ¥è¯†ã€‚\n",
    "\n",
    "**LangChain é“¾æ¥ï¼š**\n",
    "* [LC æ¦‚å¿µæ–‡æ¡£](https://docs.langchain.com/docs/)\n",
    "* [LC Python æ–‡æ¡£](https://python.langchain.com/en/latest/)\n",
    "* [LC Javascript/Typescript æ–‡æ¡£](https://js.langchain.com/docs/)\n",
    "* [LC Discord](https://discord.gg/6adMQxSpJS)\n",
    "* [www.langchain.com](https://langchain.com/)\n",
    "* [LC Twitter](https://twitter.com/LangChainAI)\n",
    "\n",
    "\n",
    "### **ä»€ä¹ˆæ˜¯LangChainï¼Ÿ**\n",
    "> LangChainæ˜¯ä¸€ä¸ªå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚\n",
    "*[æ¥æº](https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/#:~:text=LangChain%20is%20a%20framework%20for%20developing%20applications%20powered%20by%20language%20models)*\n",
    "\n",
    "**ç®€è€Œè¨€ä¹‹**ï¼šLangChainä½¿å¾—ä¸AIæ¨¡å‹çš„å·¥ä½œå’Œæ„å»ºçš„å¤æ‚éƒ¨åˆ†å˜å¾—æ›´ç®€å•ã€‚å®ƒé€šè¿‡ä¸¤ç§æ–¹å¼å¸®åŠ©å®ç°è¿™ä¸€ç‚¹ï¼š\n",
    "\n",
    "1. **é›†æˆ** - å°†å¤–éƒ¨æ•°æ®ï¼Œå¦‚æ‚¨çš„æ–‡ä»¶ã€å…¶ä»–åº”ç”¨ç¨‹åºå’Œapiæ•°æ®ï¼Œå¸¦åˆ°æ‚¨çš„LLMä¸­\n",
    "2. **ä»£ç†** - å…è®¸æ‚¨çš„LLMé€šè¿‡å†³ç­–ä¸å…¶ç¯å¢ƒäº’åŠ¨ã€‚ä½¿ç”¨LLMå¸®åŠ©å†³å®šä¸‹ä¸€æ­¥é‡‡å–å“ªç§è¡ŒåŠ¨\n",
    "\n",
    "### **ä¸ºä»€ä¹ˆé€‰æ‹©LangChainï¼Ÿ**\n",
    "1. **ç»„ä»¶** - LangChainä½¿å¾—æ›´æ¢ä¸è¯­è¨€æ¨¡å‹å·¥ä½œæ‰€éœ€çš„æŠ½è±¡å’Œç»„ä»¶å˜å¾—å®¹æ˜“ã€‚\n",
    "\n",
    "2. **å®šåˆ¶é“¾** - LangChainæä¾›äº†ä½¿ç”¨å’Œå®šåˆ¶â€œé“¾â€ï¼ˆä¸€ç³»åˆ—ä¸²è”èµ·æ¥çš„åŠ¨ä½œï¼‰çš„å¼€ç®±å³ç”¨æ”¯æŒã€‚\n",
    "\n",
    "3. **é€Ÿåº¦ ğŸš¢** - è¿™ä¸ªå›¢é˜Ÿçš„å¼€å‘é€Ÿåº¦æå¿«ã€‚æ‚¨å°†èƒ½å¤ŸåŠæ—¶äº†è§£æœ€æ–°çš„LLMç‰¹æ€§ã€‚\n",
    "\n",
    "4. **ç¤¾åŒº ğŸ‘¥** - ç²¾å½©çš„[discord](https://discord.gg/6adMQxSpJS)å’Œç¤¾åŒºæ”¯æŒï¼Œèšä¼šï¼Œé»‘å®¢æ¾ç­‰ã€‚\n",
    "\n",
    "è™½ç„¶LLMå¯ä»¥å¾ˆç›´æ¥ï¼ˆæ–‡æœ¬è¾“å…¥ï¼Œæ–‡æœ¬è¾“å‡ºï¼‰ï¼Œä½†ä¸€æ—¦æ‚¨å¼€å‘æ›´å¤æ‚çš„åº”ç”¨ç¨‹åºï¼Œæ‚¨å°†å¾ˆå¿«é‡åˆ°LangChainå¯ä»¥å¸®åŠ©è§£å†³çš„æ‘©æ“¦ç‚¹ã€‚\n",
    "\n",
    "### **ä¸»è¦ç”¨ä¾‹**\n",
    "\n",
    "* **æ‘˜è¦** - è¡¨è¾¾æ–‡æœ¬æˆ–èŠå¤©äº’åŠ¨ä¸­æœ€é‡è¦çš„äº‹å®\n",
    "* **æ–‡æ¡£é—®é¢˜ä¸å›ç­”** - ä½¿ç”¨æ–‡æ¡£ä¸­çš„ä¿¡æ¯å›ç­”é—®é¢˜æˆ–æŸ¥è¯¢\n",
    "* **æå–** - ä»æ–‡æœ¬æˆ–ç”¨æˆ·æŸ¥è¯¢ä¸­æå–ç»“æ„åŒ–æ•°æ®\n",
    "* **è¯„ä¼°** - ç†è§£æ‚¨çš„åº”ç”¨ç¨‹åºè¾“å‡ºçš„è´¨é‡\n",
    "* **æŸ¥è¯¢è¡¨æ ¼æ•°æ®** - ä»æ•°æ®åº“æˆ–å…¶ä»–è¡¨æ ¼æ•°æ®æºä¸­æå–æ•°æ®\n",
    "* **ä»£ç ç†è§£** - å¯¹ä»£ç è¿›è¡Œæ¨ç†å’Œè§£æ\n",
    "* **ä¸APIäº¤äº’** - æŸ¥è¯¢APIå¹¶ä¸å¤–éƒ¨ä¸–ç•Œè¿›è¡Œäº¤äº’\n",
    "* **èŠå¤©æœºå™¨äºº** - ä¸€ä¸ªåœ¨èŠå¤©ç•Œé¢ä¸­ä¸ç”¨æˆ·è¿›è¡Œæ¥å›äº¤äº’å¹¶ç»“åˆè®°å¿†çš„æ¡†æ¶\n",
    "* **ä»£ç†** - ä½¿ç”¨LLMå¯¹ä¸‹ä¸€æ­¥è¦åšçš„å†³ç­–è¿›è¡Œå†³ç­–ã€‚ä½¿ç”¨å·¥å…·æ¥å®ç°è¿™äº›å†³ç­–ã€‚\n",
    "\n",
    "æƒ³è¦çœ‹åˆ°è¿™äº›ç”¨ä¾‹çš„å®é™…ç¤ºä¾‹å—ï¼Ÿè¯·å‰å¾€[LangChain é¡¹ç›®ç”»å»Š](https://github.com/gkamradt/langchain-tutorials)\n",
    "\n",
    "#### **ä½œè€…è¯´æ˜:**\n",
    "\n",
    "* æœ¬æ–‡æ¡£ä¸ä¼šæ¶µç›–LangChainçš„æ‰€æœ‰æ–¹é¢ã€‚å®ƒçš„å†…å®¹ç»è¿‡ç²¾å¿ƒç­–åˆ’ï¼Œæ—¨åœ¨è®©æ‚¨å°½å¿«æ„å»ºå’Œäº§ç”Ÿå½±å“ã€‚æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[LangChain æŠ€æœ¯æ–‡æ¡£](https://python.langchain.com/en/latest/index.html)\n",
    "* æœ¬ç¬”è®°æœ¬å‡è®¾æ‚¨å·²ç»çœ‹è¿‡æœ¬ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†[åŸºç¡€çŸ¥è¯†](https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%201%20-%20Fundamentals.ipynb)ã€‚æœ¬ç¬”è®°æœ¬ä¾§é‡äºå¦‚ä½•åº”ç”¨è¿™äº›åŸºç¡€çŸ¥è¯†ã€‚\n",
    "* æ‚¨ä¼šæ³¨æ„åˆ°æˆ‘åœ¨æ•´ä¸ªç¬”è®°æœ¬ä¸­é‡å¤å¯¼å…¥è¯­å¥ã€‚æˆ‘çš„æ„å›¾æ˜¯å€¾å‘äºæ¸…æ™°ï¼Œå¹¶å¸®åŠ©æ‚¨åœ¨ä¸€ä¸ªåœ°æ–¹çœ‹åˆ°å®Œæ•´çš„ä»£ç å—ã€‚æ— éœ€æ¥å›æŸ¥çœ‹æˆ‘ä»¬ä½•æ—¶å¯¼å…¥äº†ä¸€ä¸ªåŒ…ã€‚\n",
    "* æˆ‘ä»¬åœ¨æ•´ä¸ªç¬”è®°æœ¬ä¸­ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼Œå½“æ—¶å®ƒä»¬æ˜¯davinci-003å’Œgpt-3.5-turboã€‚æ¯«æ— ç–‘é—®ï¼Œä½¿ç”¨GPT4ä¼šè·å¾—æ›´å¥½çš„ç»“æœã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬å¼€å§‹å§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æ•´ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨OpenAIçš„å„ç§[æ¨¡å‹](https://platform.openai.com/docs/models/overview)ã€‚LangChainä½¿å¾—[æ›¿æ¢LLMs](https://langchain.com/integrations.html#:~:text=integrations%20LangChain%20provides.-,LLMs,-LLM%20Provider)å˜å¾—å®¹æ˜“ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥è‡ªå·±é€‰æ‹©LLMï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY', 'YourAPIKeyIfNotSet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell if you want to make your display wider\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain ä½¿ç”¨æ¡ˆä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ‘˜è¦\n",
    "\n",
    "LangChain å’Œ LLMs æœ€å¸¸è§çš„ç”¨ä¾‹ä¹‹ä¸€æ˜¯æ‘˜è¦ã€‚æ‚¨å¯ä»¥å¯¹ä»»ä½•æ–‡æœ¬è¿›è¡Œæ‘˜è¦ï¼Œä½†ç”¨ä¾‹åŒ…æ‹¬å¯¹ç”µè¯ã€æ–‡ç« ã€ä¹¦ç±ã€å­¦æœ¯è®ºæ–‡ã€æ³•å¾‹æ–‡ä»¶ã€ç”¨æˆ·å†å²ã€è¡¨æ ¼æˆ–è´¢åŠ¡æ–‡ä»¶è¿›è¡Œæ‘˜è¦ã€‚æ‹¥æœ‰ä¸€ä¸ªå¯ä»¥å¿«é€Ÿæ€»ç»“ä¿¡æ¯çš„å·¥å…·éå¸¸æœ‰å¸®åŠ©ã€‚\n",
    "\n",
    "* **ç¤ºä¾‹** - [å¯¹B2Bé”€å”®ç”µè¯è¿›è¡Œæ‘˜è¦](https://www.youtube.com/watch?v=DIw4rbpI9ic)\n",
    "* **ç”¨ä¾‹** - å¯¹æ–‡ç« ã€æˆç»©å•ã€èŠå¤©è®°å½•ã€Slack/Discordã€å®¢æˆ·äº’åŠ¨ã€åŒ»å­¦è®ºæ–‡ã€æ³•å¾‹æ–‡ä»¶ã€æ’­å®¢ã€æ¨ç‰¹ä¸²ã€ä»£ç åº“ã€äº§å“è¯„è®ºã€è´¢åŠ¡æ–‡ä»¶è¿›è¡Œæ‘˜è¦\n",
    "\n",
    "### å¯¹çŸ­æ–‡æœ¬çš„æ‘˜è¦\n",
    "\n",
    "å¯¹çŸ­æ–‡æœ¬è¿›è¡Œæ‘˜è¦çš„æ–¹æ³•å¾ˆç®€å•ï¼Œäº‹å®ä¸Šï¼Œé™¤äº†ç®€å•æç¤ºå’Œè¯´æ˜å¤–ï¼Œæ‚¨ä¸éœ€è¦åšä»»ä½•èŠ±å“¨çš„äº‹æƒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Note, the default model is already 'text-davinci-003' but I call it out here explicitly so you know where to change it later if you want\n",
    "llm = OpenAI(temperature=0, model_name='text-davinci-003', openai_api_key=openai_api_key)\n",
    "\n",
    "# Create our template\n",
    "template = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old would understand.\n",
    "\n",
    "%TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# Create a LangChain prompt template that we can insert values to later\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬åœ¨ç½‘ä¸Šæ‰¾ä¸€ä¸ªä»¤äººå›°æƒ‘çš„æ–‡æœ¬ã€‚*[æ¥æº](https://www.smithsonianmag.com/smart-news/long-before-trees-overtook-the-land-earth-was-covered-by-giant-mushrooms-13709647/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusing_text = \"\"\"\n",
    "For the next 130 years, debate raged.\n",
    "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
    "â€œThe problem is that when you look up close at the anatomy, itâ€™s evocative of a lot of different things, but itâ€™s diagnostic of nothing,â€ says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
    "â€œAnd itâ€™s so damn big that when whenever someone says itâ€™s something, everyone elseâ€™s hackles get up: â€˜How could you have a lichen 20 feet tall?â€™â€\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬çœ‹çœ‹å°†å‘é€ç»™LLMçš„æç¤ºæ˜¯ä»€ä¹ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Prompt Begin -------\n",
      "\n",
      "%INSTRUCTIONS:\n",
      "Please summarize the following piece of text.\n",
      "Respond in a manner that a 5 year old would understand.\n",
      "\n",
      "%TEXT:\n",
      "\n",
      "For the next 130 years, debate raged.\n",
      "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
      "â€œThe problem is that when you look up close at the anatomy, itâ€™s evocative of a lot of different things, but itâ€™s diagnostic of nothing,â€ says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
      "â€œAnd itâ€™s so damn big that when whenever someone says itâ€™s something, everyone elseâ€™s hackles get up: â€˜How could you have a lichen 20 feet tall?â€™â€\n",
      "\n",
      "\n",
      "------- Prompt End -------\n"
     ]
    }
   ],
   "source": [
    "print (\"------- Prompt Begin -------\")\n",
    "\n",
    "final_prompt = prompt.format(text=confusing_text)\n",
    "print(final_prompt)\n",
    "\n",
    "print (\"------- Prompt End -------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åè®©æˆ‘ä»¬é€šè¿‡LLMå¤„ç†ä¸€ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 130 years, people argued about what Prototaxites was. Some thought it was a lichen, some thought it was a fungus, and some thought it was a tree. But no one could agree. It was so big that it was hard to figure out what it was.\n"
     ]
    }
   ],
   "source": [
    "output = llm(final_prompt)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ç§æ–¹æ³•å¯¹äºè¾ƒé•¿çš„æ–‡æœ¬æ•ˆæœä¸é”™ï¼Œä½†æ˜¯å¯¹äºæ›´é•¿çš„æ–‡æœ¬ï¼Œç®¡ç†èµ·æ¥å¯èƒ½ä¼šå˜å¾—éº»çƒ¦ï¼Œå¹¶ä¸”ä¼šé‡åˆ°ä»¤ç‰Œé™åˆ¶ã€‚å¹¸è¿çš„æ˜¯ï¼ŒLangChainå…·æœ‰é’ˆå¯¹é€šè¿‡å®ƒä»¬çš„[load_summarize_chain](https://python.langchain.com/en/latest/use_cases/summarization.html)è¿›è¡Œæ‘˜è¦çš„ä¸åŒæ–¹æ³•çš„å¼€ç®±å³ç”¨æ”¯æŒã€‚\n",
    "\n",
    "### å¯¹é•¿æ–‡æœ¬çš„æ‘˜è¦\n",
    "\n",
    "*æ³¨æ„ï¼šè¿™ç§æ–¹æ³•ä¹Ÿé€‚ç”¨äºçŸ­æ–‡æœ¬*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªè¾ƒé•¿çš„æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we started Y Combinator we came up with the\n",
      "phrase that became our motto: Make something people want.  We've\n",
      "learned a lot since then, but if I were choosing now that's still\n",
      "the one I'd pick.\n"
     ]
    }
   ],
   "source": [
    "with open('data/PaulGrahamEssays/good.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Printing the first 285 characters as a preview\n",
    "print (text[:285])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åè®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹è¿™ä¸ªæ–‡æ¡£ä¸­æœ‰å¤šå°‘ä¸ªæ ‡è®°ã€‚[get_num_tokens](https://python.langchain.com/en/latest/reference/modules/llms.html#langchain.llms.OpenAI.get_num_tokens) æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ–¹æ³•æ¥åšè¿™ä»¶äº‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3970 tokens in your file\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"There are {num_tokens} tokens in your file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è™½ç„¶ä½ å¯èƒ½å¯ä»¥æŠŠè¿™æ®µæ–‡æœ¬æ”¾å…¥ä½ çš„æç¤ºä¸­ï¼Œä½†è®©æˆ‘ä»¬å‡è£…å®ƒå¤ªå¤§äº†ï¼Œéœ€è¦å¦ä¸€ç§æ–¹æ³•ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶åˆ†å‰²ã€‚è¿™ä¸ªè¿‡ç¨‹å«åšâ€œåˆ†å—â€æˆ–â€œåˆ†å‰²â€ä½ çš„æ–‡æœ¬æˆå°å—ã€‚æˆ‘å–œæ¬¢[RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)ï¼Œå› ä¸ºå®ƒå¾ˆå®¹æ˜“æ§åˆ¶ï¼Œä½†ä½ ä¹Ÿå¯ä»¥å°è¯•ä¸€äº›[å…¶ä»–æ–¹æ³•](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now have 4 docs intead of 1 piece of text\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½ä¸€ä¸ªé“¾ï¼Œå®ƒå°†è¿ç»­è°ƒç”¨LLMã€‚æƒ³è¦æŸ¥çœ‹ä¸‹é¢é“¾ä¸­ä½¿ç”¨çš„æç¤ºå—ï¼Ÿè¯·æŸ¥çœ‹[LangChain documentation](https://github.com/hwchase17/langchain/blob/master/langchain/chains/summarize/map_reduce_prompt.py)\n",
    "\n",
    "æœ‰å…³é“¾ç±»å‹ä¹‹é—´çš„åŒºåˆ«ï¼Œè¯·æŸ¥çœ‹è¿™ä¸ªå…³äº[ä»¤ç‰Œé™åˆ¶çš„è§£å†³æ–¹æ³•](https://youtu.be/f9_BWhCI4Zo)çš„è§†é¢‘ã€‚\n",
    "\n",
    "*æ³¨æ„ï¼šæ‚¨è¿˜å¯ä»¥å°†map_reduceçš„å‰4æ¬¡è°ƒç”¨å¹¶è¡Œè¿è¡Œ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your chain ready to use\n",
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce') # verbose=True optional to see what is getting sent to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This essay looks at the idea of benevolence in startups, and how it can help them succeed. It explains how benevolence can improve morale, make people want to help, and help startups be decisive. It also looks at how markets have evolved to value potential dividends and potential earnings, and how users dislike their new operating system. The author argues that starting a company with benevolent aims is currently undervalued, and that Y Combinator's motto of \"Make something people want\" is a powerful concept.\n"
     ]
    }
   ],
   "source": [
    "# Use it. This will run through the 4 documents, summarize the chunks, then get a summary of the summary.\n",
    "output = chain.run(docs)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡è¿›è¡Œé—®ç­”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[LangChain é—®ç­”æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/question_answering.html)*\n",
    "\n",
    "ä¸ºäº†ä½¿ç”¨LLMè¿›è¡Œé—®ç­”ï¼Œæˆ‘ä»¬å¿…é¡»ï¼š\n",
    "\n",
    "1. ä¸ºLLMæä¾›å›ç­”é—®é¢˜æ‰€éœ€çš„ç›¸å…³ä¸Šä¸‹æ–‡\n",
    "2. æå‡ºæˆ‘ä»¬æƒ³è¦å›ç­”çš„é—®é¢˜\n",
    "\n",
    "ç®€åŒ–è€Œè¨€ï¼Œè¿™ä¸ªè¿‡ç¨‹çœ‹èµ·æ¥åƒè¿™æ · \"llm(æ‚¨çš„ä¸Šä¸‹æ–‡ + æ‚¨çš„é—®é¢˜) = æ‚¨çš„ç­”æ¡ˆ\"\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - [é—®ä¸€æœ¬ä¹¦](https://youtu.be/h0DHDp1FbmQ), [å‘æ‚¨çš„è‡ªå®šä¹‰æ–‡ä»¶æé—®](https://youtu.be/EnT-ZTrcPrg), [Chat Your Data JS (1000é¡µè´¢åŠ¡æŠ¥å‘Š)](https://www.youtube.com/watch?v=Ix9WIZpArm0&t=1051s), [LangChain é—®ç­”ç½‘ç»œç ”è®¨ä¼š](https://www.crowdcast.io/c/rh66hcwivly0)\n",
    "* **ç¤ºä¾‹** - [ChatPDF](https://www.chatpdf.com/)\n",
    "* **ç”¨ä¾‹** - ä¸æ‚¨çš„æ–‡æ¡£äº¤è°ˆï¼Œå‘å­¦æœ¯è®ºæ–‡æé—®ï¼Œåˆ›å»ºå­¦ä¹ æŒ‡å—ï¼Œå‚è€ƒåŒ»å­¦ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç®€å•é—®ç­”ç¤ºä¾‹\n",
    "\n",
    "åœ¨è¿™é‡Œï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹â€œllm(æ‚¨çš„ä¸Šä¸‹æ–‡ + æ‚¨çš„é—®é¢˜) = æ‚¨çš„ç­”æ¡ˆâ€çš„æƒ¯ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Rachel is 30 years old\n",
    "Bob is 45 years old\n",
    "Kevin is 65 years old\n",
    "\"\"\"\n",
    "\n",
    "question = \"Who is under 40 years old?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åå°†å®ƒä»¬ç»„åˆèµ·æ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel is under 40 years old.\n"
     ]
    }
   ],
   "source": [
    "output = llm(context + question)\n",
    "\n",
    "# I strip the text to remove the leading and trailing whitespace\n",
    "print (output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "éšç€æˆ‘ä»¬æå‡å¤æ‚åº¦ï¼Œæˆ‘ä»¬å°†æ›´å¤šåœ°åˆ©ç”¨è¿™ä¸ªæƒ¯ä¾‹ã€‚\n",
    "\n",
    "å½“æ‚¨éœ€è¦é€‰æ‹©æ€§åœ°å°†æ•°æ®æ”¾å…¥æ‚¨çš„ä¸Šä¸‹æ–‡ä¸­æ—¶ï¼Œå›°éš¾ä¹‹å¤„åœ¨äº*æ‚¨*æ”¾å…¥ä¸Šä¸‹æ–‡çš„æ•°æ®ã€‚è¿™ä¸ªç ”ç©¶é¢†åŸŸè¢«ç§°ä¸ºâ€œ[æ–‡æ¡£æ£€ç´¢](https://python.langchain.com/en/latest/modules/indexes/retrievers.html)â€ï¼Œä¸AIè®°å¿†ç´§å¯†ç›¸è¿ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨åµŒå…¥\n",
    "\n",
    "æˆ‘éæ­£å¼åœ°ç§°æˆ‘ä»¬å³å°†è¿›è¡Œçš„è¿‡ç¨‹ä¸ºâ€œå‘é‡å­˜å‚¨èˆè¹ˆâ€ã€‚è¿™ä¸ªè¿‡ç¨‹æ¶‰åŠå°†æ–‡æœ¬åˆ†å‰²ã€åµŒå…¥å—ã€å°†åµŒå…¥æ”¾å…¥æ•°æ®åº“ï¼Œç„¶åæŸ¥è¯¢å®ƒä»¬ã€‚æœ‰å…³æ­¤å†…å®¹çš„å®Œæ•´è§†é¢‘ï¼Œè¯·å‚é˜…[å¦‚ä½•é—®ä¸€æœ¬ä¹¦](https://www.youtube.com/watch?v=h0DHDp1FbmQ)\n",
    "\n",
    "æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€‰æ‹©æˆ‘ä»¬é•¿æ–‡æœ¬çš„ç›¸å…³å—ï¼Œä½†æˆ‘ä»¬åº”è¯¥é€‰æ‹©å“ªäº›å—å‘¢ï¼Ÿæœ€æµè¡Œçš„æ–¹æ³•æ˜¯åŸºäºæ¯”è¾ƒå‘é‡åµŒå…¥æ¥é€‰æ‹©*ç›¸ä¼¼*çš„æ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "# The vectorstore we'll be using\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# The LangChain component we'll use to get the documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# The easy document loader for text\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªè¾ƒé•¿çš„æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 74663 characters in that document\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('data/PaulGrahamEssays/worked.txt')\n",
    "doc = loader.load()\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨è®©æˆ‘ä»¬å°†é•¿æ–‡æ¡£åˆ†å‰²æˆå°å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 29 documents that have an average of 2,930 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of characters so we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ›å»ºæ‚¨çš„æ£€ç´¢å¼•æ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ˜¯æ—¶å€™æå‡ºä¸€ä¸ªé—®é¢˜äº†ã€‚æ£€ç´¢å™¨å°†è·å–ç›¸ä¼¼çš„æ–‡æ¡£ï¼Œå¹¶ä¸æ‚¨çš„é—®é¢˜ç»“åˆï¼Œä¾›LLMæ¨ç†ã€‚\n",
    "\n",
    "æ³¨æ„ï¼šè¿™çœ‹èµ·æ¥å¯èƒ½ä¸èµ·çœ¼ï¼Œä½†è¿™é‡Œçš„å¥‡è¿¹åœ¨äºæˆ‘ä»¬ä¸å¿…ä¼ å…¥å®Œæ•´çš„åŸå§‹æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The author describes painting as good work.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What does the author describe as good work?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ‚¨æƒ³è¦åšæ›´å¤šï¼Œæ‚¨å¯ä»¥å°†å…¶è¿æ¥åˆ°äº‘å‘é‡æ•°æ®åº“ï¼Œä½¿ç”¨ç±»ä¼¼ metal çš„å·¥å…·ï¼Œå¹¶å¼€å§‹ç®¡ç†æ‚¨çš„æ–‡æ¡£ï¼Œä»¥åŠå¤–éƒ¨æ•°æ®æº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æå–\n",
    "*[LangChain æå–æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/extraction.html)*\n",
    "\n",
    "æå–æ˜¯ä»æ–‡æœ¬ä¸­è§£ææ•°æ®çš„è¿‡ç¨‹ã€‚è¿™é€šå¸¸ç”¨äºè¾“å‡ºè§£æï¼Œä»¥ä¾¿*ç»“æ„åŒ–*æˆ‘ä»¬çš„æ•°æ®ã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - [ä½¿ç”¨LLMä»æ–‡æœ¬ä¸­æå–æ•°æ®ï¼ˆä¸“å®¶çº§æ–‡æœ¬æå–ï¼‰](https://youtu.be/xZzvwR9jdPA), [ä»OpenAIä¸­æå–ç»“æ„åŒ–è¾“å‡ºï¼ˆæ¸…ç†è„æ•°æ®ï¼‰](https://youtu.be/KwAXfey-xQk)\n",
    "* **ç¤ºä¾‹** - [OpeningAttributes](https://twitter.com/GregKamradt/status/1646500373837008897)\n",
    "* **ç”¨ä¾‹:** ä»å¥å­ä¸­æå–ç»“æ„åŒ–è¡Œä»¥æ’å…¥æ•°æ®åº“ï¼Œä»é•¿æ–‡æ¡£ä¸­æå–å¤šè¡Œä»¥æ’å…¥æ•°æ®åº“ï¼Œä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å‚æ•°ä»¥è¿›è¡ŒAPIè°ƒç”¨\n",
    "\n",
    "ä¸€ä¸ªæµè¡Œçš„æå–åº“æ˜¯[Kor](https://eyurtsev.github.io/kor/)ã€‚æˆ‘ä»¬ä»Šå¤©ä¸ä¼šæ¶‰åŠå®ƒï¼Œä½†æˆ‘å¼ºçƒˆå»ºè®®æ‚¨æŸ¥çœ‹å®ƒï¼Œä»¥è¿›è¡Œé«˜çº§æå–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help construct our Chat Messages\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# We will be using a chat model, defaults to gpt-3.5-turbo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# To parse outputs and get structured data back\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŸå§‹æå–\n",
    "\n",
    "è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å¼€å§‹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘åªæ˜¯æä¾›äº†ä¸€ä¸ªå¸¦æœ‰è¾“å‡ºç±»å‹è¯´æ˜çš„æç¤ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You will be given a sentence with fruit names, extract those fruit names and assign an emoji to them\n",
    "Return the fruit name and emojis in a python dictionary\n",
    "\"\"\"\n",
    "\n",
    "fruit_names = \"\"\"\n",
    "Apple, Pear, this is an kiwi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': 'ğŸ', 'Pear': 'ğŸ', 'kiwi': 'ğŸ¥'}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Make your prompt which combines the instructions w/ the fruit names\n",
    "prompt = (instructions + fruit_names)\n",
    "\n",
    "# Call the LLM\n",
    "output = chat_model([HumanMessage(content=prompt)])\n",
    "\n",
    "print (output.content)\n",
    "print (type(output.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªåˆé€‚çš„Pythonå­—å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': 'ğŸ', 'Pear': 'ğŸ', 'kiwi': 'ğŸ¥'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "output_dict = eval(output.content)\n",
    "\n",
    "print (output_dict)\n",
    "print (type(output_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è™½ç„¶è¿™æ¬¡æœ‰æ•ˆï¼Œä½†å¯¹äºæ›´é«˜çº§çš„ç”¨ä¾‹æ¥è¯´ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªé•¿æœŸå¯é çš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨LangChainçš„å“åº”æ¨¡å¼\n",
    "\n",
    "LangChainçš„å“åº”æ¨¡å¼å°†ä¸ºæˆ‘ä»¬åšä¸¤ä»¶äº‹ï¼š\n",
    "\n",
    "1. è‡ªåŠ¨ç”Ÿæˆå¸¦æœ‰çœŸå®æ ¼å¼è¯´æ˜çš„æç¤ºã€‚è¿™å¾ˆæ£’ï¼Œå› ä¸ºæˆ‘ä¸éœ€è¦æ‹…å¿ƒæç¤ºå·¥ç¨‹æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘ä¼šæŠŠè¿™ä¸ªäº¤ç»™LangChainï¼\n",
    "\n",
    "2. ä»LLMçš„è¾“å‡ºä¸­è¯»å–æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºé€‚å½“çš„Pythonå¯¹è±¡\n",
    "\n",
    "åœ¨è¿™é‡Œï¼Œæˆ‘å®šä¹‰äº†æˆ‘æƒ³è¦çš„æ¨¡å¼ã€‚æˆ‘å°†ä»ä¼ªèŠå¤©æ¶ˆæ¯ä¸­æå–ç”¨æˆ·æƒ³è¦æ’­æ”¾çš„æ­Œæ›²å’Œè‰ºæœ¯å®¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schema I want out\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"artist\", description=\"The name of the musical artist\"),\n",
    "    ResponseSchema(name=\"song\", description=\"The name of the song that the artist plays\")\n",
    "]\n",
    "\n",
    "# The parser that will look for the LLM output in my schema and return it back to me\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# The format instructions that LangChain makes. Let's look at them\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt template that brings it all together\n",
    "# Note: This is a different prompt template than before because we are using a Chat Model\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"Given a command from the user, extract the artist and song names \\n \\\n",
    "                                                    {format_instructions}\\n{user_prompt}\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a command from the user, extract the artist and song names \n",
      "                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n",
      "I really like So Young by Portugal. The Man\n"
     ]
    }
   ],
   "source": [
    "fruit_query = prompt.format_prompt(user_prompt=\"I really like So Young by Portugal. The Man\")\n",
    "print (fruit_query.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist': 'Portugal. The Man', 'song': 'So Young'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "fruit_output = chat_model(fruit_query.to_messages())\n",
    "output = output_parser.parse(fruit_output.content)\n",
    "\n",
    "print (output)\n",
    "print (type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªå­—å…¸ï¼Œä»¥åå¯ä»¥ç”¨ã€‚\n",
    "\n",
    "<span style=\"background:#fff5d6\">è­¦å‘Šï¼š</span> è§£æå™¨å¯»æ‰¾ç‰¹å®šæ ¼å¼çš„LLMè¾“å‡ºã€‚æ‚¨çš„æ¨¡å‹å¯èƒ½ä¸ä¼šæ¯æ¬¡éƒ½è¾“å‡ºç›¸åŒçš„æ ¼å¼ã€‚ç¡®ä¿ä½¿ç”¨æ­¤æ–¹æ³•å¤„ç†é”™è¯¯ã€‚GPT4å’Œæœªæ¥çš„è¿­ä»£ç‰ˆæœ¬å°†æ›´åŠ å¯é ã€‚\n",
    "\n",
    "è¦è¿›è¡Œæ›´é«˜çº§çš„è§£æï¼Œè¯·æŸ¥çœ‹[Kor](https://eyurtsev.github.io/kor/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯„ä¼°\n",
    "\n",
    "*[LangChain è¯„ä¼°æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/evaluation.html)*\n",
    "\n",
    "è¯„ä¼°æ˜¯å¯¹åº”ç”¨ç¨‹åºè¾“å‡ºè¿›è¡Œè´¨é‡æ£€æŸ¥çš„è¿‡ç¨‹ã€‚é€šå¸¸ï¼Œç¡®å®šæ€§çš„ä»£ç æœ‰æˆ‘ä»¬å¯ä»¥è¿è¡Œçš„æµ‹è¯•ï¼Œä½†ç”±äºè‡ªç„¶è¯­è¨€çš„ä¸ç¡®å®šæ€§å’Œå¯å˜æ€§ï¼Œè¯„ä¼°LLMçš„è¾“å‡ºæ›´åŠ å›°éš¾ã€‚LangChainæä¾›äº†å¸®åŠ©æˆ‘ä»¬åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­çš„å·¥å…·ã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - å³å°†æ¨å‡º\n",
    "* **ç¤ºä¾‹** - [Lance Martinçš„é«˜çº§](https://twitter.com/RLanceMartin) [è‡ªåŠ¨è¯„ä¼°å™¨](https://github.com/rlancemartin/auto-evaluator)\n",
    "* **ç”¨ä¾‹:** å¯¹æ‚¨çš„æ‘˜è¦æˆ–é—®ç­”æµç¨‹è¿è¡Œè´¨é‡æ£€æŸ¥ï¼Œæ£€æŸ¥æ‚¨çš„æ‘˜è¦æµç¨‹çš„è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings, store, and retrieval\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Model and doc loader\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Eval!\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 74663 characters in that document\n"
     ]
    }
   ],
   "source": [
    "# Our long essay from before\n",
    "loader = TextLoader('data/PaulGrahamEssays/worked.txt')\n",
    "doc = loader.load()\n",
    "\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆè®©æˆ‘ä»¬è¿›è¡Œå‘é‡å­˜å‚¨çš„æ“ä½œï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œé—®ç­”äº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 29 documents that have an average of 2,930 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)\n",
    "\n",
    "# Get the total number of characters so we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings and docstore\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ›å»ºæ‚¨çš„æ£€ç´¢å¼•æ“ã€‚è¯·æ³¨æ„ï¼Œç°åœ¨æˆ‘æœ‰ä¸€ä¸ª`input_key`å‚æ•°ã€‚è¿™å‘Šè¯‰é“¾æ¡æˆ‘æä¾›çš„å­—å…¸ä¸­å“ªä¸ªé”®åŒ…å«æˆ‘çš„æç¤º/æŸ¥è¯¢ã€‚æˆ‘æŒ‡å®š`question`ä»¥åŒ¹é…ä¸‹é¢å­—å…¸ä¸­çš„é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(), input_key=\"question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘å°†å‘LLMä¼ é€’ä¸€ä¸ªé—®é¢˜åˆ—è¡¨å’Œæˆ‘çŸ¥é“æ˜¯æ­£ç¡®çš„çœŸå®ç­”æ¡ˆï¼ˆæˆ‘ä½œä¸ºäººç±»éªŒè¯è¿‡ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers = [\n",
    "    {'question' : \"Which company sold the microcomputer kit that his friend built himself?\", 'answer' : 'Healthkit'},\n",
    "    {'question' : \"What was the small city he talked about in the city that is the financial capital of USA?\", 'answer' : 'Yorkville, NY'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘å°†ä½¿ç”¨`chain.apply`åˆ†åˆ«è¿è¡Œæˆ‘çš„ä¸¤ä¸ªé—®é¢˜ã€‚\n",
    "\n",
    "å…¶ä¸­ä¸€ä¸ªå¾ˆé…·çš„éƒ¨åˆ†æ˜¯ï¼Œæˆ‘å°†å¾—åˆ°ä¸€ä¸ªåŒ…å«é—®é¢˜å’Œç­”æ¡ˆçš„å­—å…¸åˆ—è¡¨ï¼Œä½†å­—å…¸ä¸­è¿˜ä¼šæœ‰å¦ä¸€ä¸ªé”®`result`ï¼Œè¿™å°†æ˜¯LLMçš„è¾“å‡ºã€‚\n",
    "\n",
    "æ³¨æ„ï¼šæˆ‘ç‰¹æ„è®©æˆ‘çš„ç¬¬äºŒä¸ªé—®é¢˜å«ç³Šä¸æ¸…ï¼Œå¾ˆéš¾ä¸€æ¬¡å›ç­”æ­£ç¡®ï¼Œè¿™æ ·LLMä¼šå›ç­”é”™è¯¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Which company sold the microcomputer kit that his friend built himself?',\n",
       "  'answer': 'Healthkit',\n",
       "  'result': ' The microcomputer kit was sold by Heathkit.'},\n",
       " {'question': 'What was the small city he talked about in the city that is the financial capital of USA?',\n",
       "  'answer': 'Yorkville, NY',\n",
       "  'result': ' The small city he talked about is New York City, which is the financial capital of the United States.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = chain.apply(question_answers)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åè®©LLMå°†æˆ‘çš„çœŸå®ç­”æ¡ˆï¼ˆ`answer`é”®ï¼‰ä¸LLMçš„ç»“æœï¼ˆ`result`é”®ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬è¦æ±‚LLMå¯¹è‡ªå·±è¿›è¡Œè¯„åˆ†ã€‚æˆ‘ä»¬ç”Ÿæ´»åœ¨ä¸€ä¸ªç–¯ç‹‚çš„ä¸–ç•Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your eval chain\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "# Have it grade itself. The code below helps the eval_chain know where the different parts are\n",
    "graded_outputs = eval_chain.evaluate(question_answers,\n",
    "                                     predictions,\n",
    "                                     question_key=\"question\",\n",
    "                                     prediction_key=\"result\",\n",
    "                                     answer_key='answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' CORRECT'}, {'text': ' INCORRECT'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™æ˜¯æ­£ç¡®çš„ï¼è¯·æ³¨æ„ï¼Œé—®é¢˜ï¼ƒ1çš„ç­”æ¡ˆæ˜¯â€œHealthkitâ€ï¼Œè€Œé¢„æµ‹æ˜¯â€œè¯¥å¾®å‹è®¡ç®—æœºå¥—ä»¶ç”±Heathkitå‡ºå”®â€ã€‚LLMçŸ¥é“ç­”æ¡ˆå’Œç»“æœæ˜¯ç›¸åŒçš„ï¼Œå¹¶ç»™äº†æˆ‘ä»¬ä¸€ä¸ªâ€œæ­£ç¡®â€çš„æ ‡ç­¾ã€‚å¤ªæ£’äº†ã€‚\n",
    "\n",
    "å¯¹äºé—®é¢˜ï¼ƒ2ï¼Œå®ƒçŸ¥é“å®ƒä»¬ä¸ç›¸åŒï¼Œå¹¶ç»™äº†æˆ‘ä»¬ä¸€ä¸ªâ€œä¸æ­£ç¡®â€çš„æ ‡ç­¾ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŸ¥è¯¢è¡¨æ ¼æ•°æ®\n",
    "\n",
    "*[LangChain æŸ¥è¯¢è¡¨æ ¼æ•°æ®æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/tabular.html)*\n",
    "\n",
    "ä¸–ç•Œä¸Šæœ€å¸¸è§çš„æ•°æ®ç±»å‹æ˜¯è¡¨æ ¼å½¢å¼çš„ï¼ˆå¥½å§ï¼Œé™¤äº†éç»“æ„åŒ–æ•°æ®ï¼‰ã€‚èƒ½å¤Ÿä½¿ç”¨LangChainæŸ¥è¯¢è¿™äº›æ•°æ®å¹¶å°†å…¶ä¼ é€’ç»™LLMéå¸¸å¼ºå¤§ã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - å³å°†æ¨å‡º\n",
    "* **ç¤ºä¾‹** - å¾…å®š\n",
    "* **ç”¨ä¾‹:** ä½¿ç”¨LLMæŸ¥è¯¢ç”¨æˆ·æ•°æ®ï¼Œè¿›è¡Œæ•°æ®åˆ†æï¼Œä»æ•°æ®åº“è·å–å®æ—¶ä¿¡æ¯\n",
    "\n",
    "è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹â€œä»£ç† + è¡¨æ ¼æ•°æ®â€ï¼ˆ[Pandas](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/pandas.html), [SQL](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html), [CSV](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/csv.html)ï¼‰\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¸€ä¸ªSQLiteæ•°æ®åº“ã€‚æˆ‘ä»¬å°†æŸ¥çœ‹[æ—§é‡‘å±±æ ‘æœ¨](https://data.sfgov.org/City-Infrastructure/Street-Tree-List/tkzw-k3nq)æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†é¦–å…ˆæŒ‡å®šæ•°æ®çš„ä½ç½®å¹¶å‡†å¤‡å¥½è¿æ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_db_path = 'data/San_Francisco_Trees.db'\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªé“¾æ¡ï¼Œå°†æˆ‘ä»¬çš„LLMå’Œæ•°æ®åº“ç»“åˆèµ·æ¥ã€‚æˆ‘è®¾ç½®`verbose=True`ï¼Œè¿™æ ·æ‚¨å¯ä»¥çœ‹åˆ°å‘ç”Ÿäº†ä»€ä¹ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregorykamradt/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/sql_database/base.py:63: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many Species of trees are there in San Francisco?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(DISTINCT \"qSpecies\") FROM \"SFTrees\";\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(578,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 578 Species of trees in San Francisco.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 578 Species of trees in San Francisco.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.run(\"How many Species of trees are there in San Francisco?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼å®é™…ä¸Šè¿™é‡Œæœ‰å‡ ä¸ªæ­¥éª¤ã€‚\n",
    "\n",
    "**æ­¥éª¤:**\n",
    "1. æ‰¾åˆ°è¦ä½¿ç”¨çš„è¡¨\n",
    "2. æ‰¾åˆ°è¦ä½¿ç”¨çš„åˆ—\n",
    "3. æ„é€ æ­£ç¡®çš„SQLæŸ¥è¯¢\n",
    "4. æ‰§è¡Œè¯¥æŸ¥è¯¢\n",
    "5. è·å–ç»“æœ\n",
    "6. è¿”å›è‡ªç„¶è¯­è¨€å“åº”\n",
    "\n",
    "è®©æˆ‘ä»¬é€šè¿‡pandasæ¥ç¡®è®¤ä¸€ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define your SQL query\n",
    "query = \"SELECT count(distinct qSpecies) FROM SFTrees\"\n",
    "\n",
    "# Read the SQL query into a Pandas DataFrame\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    }
   ],
   "source": [
    "# Display the result in the first column first cell\n",
    "print(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¾ˆå¥½ï¼ç­”æ¡ˆåŒ¹é…ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»£ç ç†è§£\n",
    "\n",
    "*[LangChain ä»£ç ç†è§£æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/code.html)*\n",
    "\n",
    "LLMæœ€ä»¤äººå…´å¥‹çš„èƒ½åŠ›ä¹‹ä¸€å°±æ˜¯ä»£ç ç†è§£ã€‚å…¨ä¸–ç•Œçš„äººä»¬éƒ½å› ä¸ºäººå·¥æ™ºèƒ½çš„å¸®åŠ©è€Œæé«˜äº†è¾“å‡ºé€Ÿåº¦å’Œè´¨é‡ã€‚å…¶ä¸­ä¸€ä¸ªé‡è¦éƒ¨åˆ†æ˜¯æ‹¥æœ‰ä¸€ä¸ªèƒ½å¤Ÿç†è§£ä»£ç å¹¶å¸®åŠ©æ‚¨å®Œæˆç‰¹å®šä»»åŠ¡çš„LLMã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - å³å°†æ¨å‡º\n",
    "* **ç¤ºä¾‹** - å¾…å®š\n",
    "* **ç”¨ä¾‹:** ç±»ä¼¼Co-Pilotçš„åŠŸèƒ½ï¼Œå¯ä»¥å¸®åŠ©å›ç­”ç‰¹å®šåº“ä¸­çš„é—®é¢˜ï¼Œå¸®åŠ©æ‚¨ç”Ÿæˆæ–°ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to read local files\n",
    "import os\n",
    "\n",
    "# Vector Support\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Model and chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Text splitters\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†å†æ¬¡è¿›è¡Œå‘é‡å­˜å‚¨çš„æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=(), openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘åœ¨è¯¥å­˜å‚¨åº“çš„æ•°æ®æ–‡ä»¶å¤¹ä¸­æ”¾äº†ä¸€ä¸ªå°çš„PythonåŒ…[The Fuzz](https://github.com/seatgeek/thefuzz)ï¼ˆä¸ªäººå–œçˆ±çš„ç‹¬ç«‹åŒ…ï¼‰ã€‚\n",
    "\n",
    "ä¸‹é¢çš„å¾ªç¯å°†éå†åº“ä¸­çš„æ¯ä¸ªæ–‡ä»¶ï¼Œå¹¶å°†å…¶åŠ è½½ä¸ºæ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data/thefuzz'\n",
    "docs = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load up the file as a doc and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of a document. It's just code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 175 documents\n",
      "\n",
      "------ Start Document ------\n",
      "import unittest\n",
      "import re\n",
      "import pycodestyle\n",
      "\n",
      "from thefuzz import fuzz\n",
      "from thefuzz import process\n",
      "from thefuzz import utils\n",
      "from thefuzz.string_processing import StringProcessor\n",
      "\n",
      "\n",
      "class StringProcessingTest(unittest.TestCase):\n",
      "    def test_replace_non_letters_non_numbers_with_whitespace(self):\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(docs)} documents\\n\")\n",
    "print (\"------ Start Document ------\")\n",
    "print (docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†å®ƒä»¬åµŒå…¥å¹¶å­˜å‚¨åœ¨æ–‡æ¡£å­˜å‚¨ä¸­ã€‚è¿™å°†ä¼šå‘OpenAIå‘å‡ºAPIè°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our retriever ready\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What function do I use if I want to find the most similar item in a list of items?\"\n",
    "output = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `process.extractOne()` function from `thefuzz` package to find the most similar item in a list of items. Here's an example:\n",
      "\n",
      "```\n",
      "from thefuzz import process\n",
      "\n",
      "choices = [\"apple\", \"banana\", \"orange\", \"pear\"]\n",
      "query = \"pineapple\"\n",
      "\n",
      "best_match = process.extractOne(query, choices)\n",
      "print(best_match)\n",
      "```\n",
      "\n",
      "This would output `(u'apple', 36)`, which means that the most similar item to \"pineapple\" in the list of choices is \"apple\", with a similarity score of 36.\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you write the code to use the process.extractOne() function? Only respond with code. No other text or explanation\"\n",
    "output = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import fuzzywuzzy.process as process\n",
      "\n",
      "choices = [\n",
      "    \"new york mets vs chicago cubs\",\n",
      "    \"chicago cubs at new york mets\",\n",
      "    \"atlanta braves vs pittsbugh pirates\",\n",
      "    \"new york yankees vs boston red sox\"\n",
      "]\n",
      "\n",
      "query = \"new york mets at chicago cubs\"\n",
      "\n",
      "best = process.extractOne(query, choices)\n",
      "print(best[0])\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸APIäº¤äº’\n",
    "\n",
    "*[LangChain APIäº¤äº’æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/apis.html)*\n",
    "\n",
    "å¦‚æœæ‚¨éœ€è¦çš„æ•°æ®æˆ–æ“ä½œä½äºAPIåé¢ï¼Œæ‚¨å°†éœ€è¦æ‚¨çš„LLMä¸APIè¿›è¡Œäº¤äº’ã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - å³å°†æ¨å‡º\n",
    "* **ç¤ºä¾‹** - å¾…å®š\n",
    "* **ç”¨ä¾‹:** ç†è§£ç”¨æˆ·çš„è¯·æ±‚å¹¶æ‰§è¡Œæ“ä½œï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–æ›´å¤šçš„ç°å®ä¸–ç•Œå·¥ä½œæµç¨‹\n",
    "\n",
    "è¿™ä¸ªä¸»é¢˜ä¸ä»£ç†å’Œæ’ä»¶å¯†åˆ‡ç›¸å…³ï¼Œå°½ç®¡æˆ‘ä»¬å°†åœ¨æœ¬èŠ‚ä¸­ç®€å•ä»‹ç»ä¸€ä¸ªç”¨ä¾‹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[LangChain + æ’ä»¶](https://python.langchain.com/en/latest/use_cases/agents/custom_agent_with_plugin_retrieval_using_plugnplai.html)æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChainçš„APIChainèƒ½å¤Ÿé˜…è¯»APIæ–‡æ¡£å¹¶ç†è§£å®ƒéœ€è¦è°ƒç”¨å“ªä¸ªç«¯ç‚¹ã€‚\n",
    "\n",
    "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘å†™äº†ï¼ˆæ•…æ„é©¬è™çš„ï¼‰APIæ–‡æ¡£æ¥æ¼”ç¤ºè¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_docs = \"\"\"\n",
    "\n",
    "BASE URL: https://restcountries.com/\n",
    "\n",
    "API Documentation:\n",
    "\n",
    "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
    "    - name: Name of country - Ex: italy, france\n",
    "    \n",
    "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
    "    - currency: 3 letter currency. Example: USD, COP\n",
    "    \n",
    "Woo! This is my documentation\n",
    "\"\"\"\n",
    "\n",
    "chain_new = APIChain.from_llm_and_api_docs(llm, api_docs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬å°è¯•è¿›è¡Œä¸€ä¸ªé’ˆå¯¹å›½å®¶ç«¯ç‚¹çš„APIè°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/france\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"RÃ©publique franÃ§aise\",\"common\":\"France\"}}},\"tld\":[\".fr\"],\"cca2\":\"FR\",\"ccn3\":\"250\",\"cca3\":\"FRA\",\"cioc\":\"FRA\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"EUR\":{\"name\":\"Euro\",\"symbol\":\"â‚¬\"}},\"idd\":{\"root\":\"+3\",\"suffixes\":[\"3\"]},\"capital\":[\"Paris\"],\"altSpellings\":[\"FR\",\"French Republic\",\"RÃ©publique franÃ§aise\"],\"region\":\"Europe\",\"subregion\":\"Western Europe\",\"languages\":{\"fra\":\"French\"},\"translations\":{\"ara\":{\"official\":\"Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±ÙŠØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©\",\"common\":\"ÙØ±Ù†Ø³Ø§\"},\"bre\":{\"official\":\"Republik FraÃ±s\",\"common\":\"FraÃ±s\"},\"ces\":{\"official\":\"FrancouzskÃ¡ republika\",\"common\":\"Francie\"},\"cym\":{\"official\":\"French Republic\",\"common\":\"France\"},\"deu\":{\"official\":\"FranzÃ¶sische Republik\",\"common\":\"Frankreich\"},\"est\":{\"official\":\"Prantsuse Vabariik\",\"common\":\"Prantsusmaa\"},\"fin\":{\"official\":\"Ranskan tasavalta\",\"common\":\"Ranska\"},\"fra\":{\"official\":\"RÃ©publique franÃ§aise\",\"common\":\"France\"},\"hrv\":{\"official\":\"Francuska Republika\",\"common\":\"Francuska\"},\"hun\":{\"official\":\"Francia KÃ¶ztÃ¡rsasÃ¡g\",\"common\":\"FranciaorszÃ¡g\"},\"ita\":{\"official\":\"Repubblica francese\",\"common\":\"Francia\"},\"jpn\":{\"official\":\"ãƒ•ãƒ©ãƒ³ã‚¹å…±å’Œå›½\",\"common\":\"ãƒ•ãƒ©ãƒ³ã‚¹\"},\"kor\":{\"official\":\"í”„ë‘ìŠ¤ ê³µí™”êµ­\",\"common\":\"í”„ë‘ìŠ¤\"},\"nld\":{\"official\":\"Franse Republiek\",\"common\":\"Frankrijk\"},\"per\":{\"official\":\"Ø¬Ù…Ù‡ÙˆØ±ÛŒ ÙØ±Ø§Ù†Ø³Ù‡\",\"common\":\"ÙØ±Ø§Ù†Ø³Ù‡\"},\"pol\":{\"official\":\"Republika Francuska\",\"common\":\"Francja\"},\"por\":{\"official\":\"RepÃºblica Francesa\",\"common\":\"FranÃ§a\"},\"rus\":{\"official\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†ÑƒĞ·ÑĞºĞ°Ñ Ğ ĞµÑĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°\",\"common\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†Ğ¸Ñ\"},\"slk\":{\"official\":\"FrancÃºzska republika\",\"common\":\"FrancÃºzsko\"},\"spa\":{\"official\":\"RepÃºblica francÃ©s\",\"common\":\"Francia\"},\"srp\":{\"official\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†ÑƒÑĞºĞ° Ğ ĞµĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°\",\"common\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†ÑƒÑĞºĞ°\"},\"swe\":{\"official\":\"Republiken Frankrike\",\"common\":\"Frankrike\"},\"tur\":{\"official\":\"Fransa Cumhuriyeti\",\"common\":\"Fransa\"},\"urd\":{\"official\":\"Ø¬Ù…ÛÙˆØ±ÛŒÛ ÙØ±Ø§Ù†Ø³\",\"common\":\"ÙØ±Ø§Ù†Ø³\"},\"zho\":{\"official\":\"æ³•å…°è¥¿å…±å’Œå›½\",\"common\":\"æ³•å›½\"}},\"latlng\":[46.0,2.0],\"landlocked\":false,\"borders\":[\"AND\",\"BEL\",\"DEU\",\"ITA\",\"LUX\",\"MCO\",\"ESP\",\"CHE\"],\"area\":551695.0,\"demonyms\":{\"eng\":{\"f\":\"French\",\"m\":\"French\"},\"fra\":{\"f\":\"FranÃ§aise\",\"m\":\"FranÃ§ais\"}},\"flag\":\"\\uD83C\\uDDEB\\uD83C\\uDDF7\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/g7QxxSFsWyTPKuzd7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/1403916\"},\"population\":67391582,\"gini\":{\"2018\":32.4},\"fifa\":\"FRA\",\"car\":{\"signs\":[\"F\"],\"side\":\"right\"},\"timezones\":[\"UTC-10:00\",\"UTC-09:30\",\"UTC-09:00\",\"UTC-08:00\",\"UTC-04:00\",\"UTC-03:00\",\"UTC+01:00\",\"UTC+02:00\",\"UTC+03:00\",\"UTC+04:00\",\"UTC+05:00\",\"UTC+10:00\",\"UTC+11:00\",\"UTC+12:00\"],\"continents\":[\"Europe\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/fr.png\",\"svg\":\"https://flagcdn.com/fr.svg\",\"alt\":\"The flag of France is composed of three equal vertical bands of blue, white and red.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/fr.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/fr.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[48.87,2.33]},\"postalCode\":{\"format\":\"#####\",\"regex\":\"^(\\\\d{5})$\"}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' France is an officially-assigned, independent country located in Western Europe. Its capital is Paris and its official language is French. Its currency is the Euro (â‚¬). It has a population of 67,391,582 and its borders are with Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain, and Switzerland.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run('Can you tell me information about france?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬å°è¯•è¿›è¡Œä¸€ä¸ªé’ˆå¯¹è´§å¸ç«¯ç‚¹çš„APIè°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/COP\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Colombia\",\"official\":\"Republic of Colombia\",\"nativeName\":{\"spa\":{\"official\":\"RepÃºblica de Colombia\",\"common\":\"Colombia\"}}},\"tld\":[\".co\"],\"cca2\":\"CO\",\"ccn3\":\"170\",\"cca3\":\"COL\",\"cioc\":\"COL\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"COP\":{\"name\":\"Colombian peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"7\"]},\"capital\":[\"BogotÃ¡\"],\"altSpellings\":[\"CO\",\"Republic of Colombia\",\"RepÃºblica de Colombia\"],\"region\":\"Americas\",\"subregion\":\"South America\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"Ø¬Ù…Ù‡ÙˆØ±ÙŠØ© ÙƒÙˆÙ„ÙˆÙ…Ø¨ÙŠØ§\",\"common\":\"ÙƒÙˆÙ„ÙˆÙ…Ø¨ÙŠØ§\"},\"bre\":{\"official\":\"Republik Kolombia\",\"common\":\"Kolombia\"},\"ces\":{\"official\":\"KolumbijskÃ¡ republika\",\"common\":\"Kolumbie\"},\"cym\":{\"official\":\"Gweriniaeth Colombia\",\"common\":\"Colombia\"},\"deu\":{\"official\":\"Republik Kolumbien\",\"common\":\"Kolumbien\"},\"est\":{\"official\":\"Colombia Vabariik\",\"common\":\"Colombia\"},\"fin\":{\"official\":\"Kolumbian tasavalta\",\"common\":\"Kolumbia\"},\"fra\":{\"official\":\"RÃ©publique de Colombie\",\"common\":\"Colombie\"},\"hrv\":{\"official\":\"Republika Kolumbija\",\"common\":\"Kolumbija\"},\"hun\":{\"official\":\"Kolumbiai KÃ¶ztÃ¡rsasÃ¡g\",\"common\":\"Kolumbia\"},\"ita\":{\"official\":\"Repubblica di Colombia\",\"common\":\"Colombia\"},\"jpn\":{\"official\":\"ã‚³ãƒ­ãƒ³ãƒ“ã‚¢å…±å’Œå›½\",\"common\":\"ã‚³ãƒ­ãƒ³ãƒ“ã‚¢\"},\"kor\":{\"official\":\"ì½œë¡¬ë¹„ì•„ ê³µí™”êµ­\",\"common\":\"ì½œë¡¬ë¹„ì•„\"},\"nld\":{\"official\":\"Republiek Colombia\",\"common\":\"Colombia\"},\"per\":{\"official\":\"Ø¬Ù…Ù‡ÙˆØ±ÛŒ Ú©Ù„Ù…Ø¨ÛŒØ§\",\"common\":\"Ú©Ù„Ù…Ø¨ÛŒØ§\"},\"pol\":{\"official\":\"Republika Kolumbii\",\"common\":\"Kolumbia\"},\"por\":{\"official\":\"RepÃºblica da ColÃ´mbia\",\"common\":\"ColÃ´mbia\"},\"rus\":{\"official\":\"Ğ ĞµÑĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ° ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ\",\"common\":\"ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ\"},\"slk\":{\"official\":\"KolumbijskÃ¡ republika\",\"common\":\"Kolumbia\"},\"spa\":{\"official\":\"RepÃºblica de Colombia\",\"common\":\"Colombia\"},\"srp\":{\"official\":\"Ğ ĞµĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ° ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ˜Ğ°\",\"common\":\"ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ˜Ğ°\"},\"swe\":{\"official\":\"Republiken Colombia\",\"common\":\"Colombia\"},\"tur\":{\"official\":\"Kolombiya Cumhuriyeti\",\"common\":\"Kolombiya\"},\"urd\":{\"official\":\"Ø¬Ù…ÛÙˆØ±ÛŒÛ Ú©ÙˆÙ„Ù…Ø¨ÛŒØ§\",\"common\":\"Ú©ÙˆÙ„Ù…Ø¨ÛŒØ§\"},\"zho\":{\"official\":\"å“¥ä¼¦æ¯”äºšå…±å’Œå›½\",\"common\":\"å“¥ä¼¦æ¯”äºš\"}},\"latlng\":[4.0,-72.0],\"landlocked\":false,\"borders\":[\"BRA\",\"ECU\",\"PAN\",\"PER\",\"VEN\"],\"area\":1141748.0,\"demonyms\":{\"eng\":{\"f\":\"Colombian\",\"m\":\"Colombian\"},\"fra\":{\"f\":\"Colombienne\",\"m\":\"Colombien\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDF4\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/RdwTG8e7gPwS62oR6\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/120027\"},\"population\":50882884,\"gini\":{\"2019\":51.3},\"fifa\":\"COL\",\"car\":{\"signs\":[\"CO\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"South America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/co.png\",\"svg\":\"https://flagcdn.com/co.svg\",\"alt\":\"The flag of Colombia is composed of three horizontal bands of yellow, blue and red, with the yellow band twice the height of the other two bands.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/co.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/co.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[4.71,-74.07]}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The currency of Colombia is the Colombian peso (COP), symbolized by the \"$\" sign.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run('Can you tell me about the currency COP?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼ŒAPIChainè¯»å–äº†è¯´æ˜å¹¶ç†è§£äº†å®ƒéœ€è¦è¿›è¡Œå“ªä¸ªAPIè°ƒç”¨ã€‚\n",
    "\n",
    "ä¸€æ—¦è¿”å›äº†å“åº”ï¼Œå®ƒå°±ä¼šè¢«è§£æï¼Œç„¶åæˆ‘çš„é—®é¢˜å°±ä¼šå¾—åˆ°å›ç­”ã€‚å¤ªæ£’äº† ğŸ’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## èŠå¤©æœºå™¨äºº\n",
    "\n",
    "*[LangChain èŠå¤©æœºå™¨äººæ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/chatbots.html)*\n",
    "\n",
    "èŠå¤©æœºå™¨äººä½¿ç”¨äº†æˆ‘ä»¬å·²ç»äº†è§£çš„è®¸å¤šå·¥å…·ï¼Œè¿˜å¢åŠ äº†ä¸€ä¸ªé‡è¦çš„ä¸»é¢˜ï¼šè®°å¿†ã€‚æœ‰å¾ˆå¤šä¸åŒç±»å‹çš„[è®°å¿†](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html)ï¼Œå¯ä»¥å°è¯•çœ‹çœ‹å“ªç§å¯¹æ‚¨æœ€åˆé€‚ã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - å³å°†æ¨å‡º\n",
    "* **ç¤ºä¾‹** - [ChatBase](https://www.chatbase.co/?via=greg) (Affiliate link), [NexusGPT](https://twitter.com/achammah1/status/1649482899253501958?s=20), [ChatPDF](https://www.chatpdf.com/)\n",
    "* **ç”¨ä¾‹:** ä¸ç”¨æˆ·è¿›è¡Œå®æ—¶äº¤äº’ï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªå¯äº¤æµçš„ç•Œé¢ï¼Œè®©ç”¨æˆ·æå‡ºè‡ªç„¶è¯­è¨€é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Chat specific components\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºè¿™ä¸ªç”¨ä¾‹ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•å®šåˆ¶æä¾›ç»™èŠå¤©æœºå™¨äººçš„ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "æ‚¨å¯ä»¥ä¼ é€’æœ‰å…³æœºå™¨äººåº”å¦‚ä½•å“åº”çš„è¯´æ˜ï¼Œè¿˜å¯ä»¥ä¼ é€’ä»»ä½•å…¶ä»–ç›¸å…³ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a chatbot that is unhelpful.\n",
    "Your goal is to not help the user but only make jokes.\n",
    "Take what the user is saying and make a joke out of it\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(openai_api_key=openai_api_key), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not help the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it\n",
      "\n",
      "\n",
      "Human: Is an pear a fruit or vegetable?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Yes, an pear is a fruit of confusion!'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Is an pear a fruit or vegetable?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not help the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it\n",
      "\n",
      "Human: Is an pear a fruit or vegetable?\n",
      "AI:  Yes, an pear is a fruit of confusion!\n",
      "Human: What was one of the fruits I first asked you about?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I think it was the fruit of knowledge!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"What was one of the fruits I first asked you about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯·æ³¨æ„ï¼Œæˆ‘çš„ç¬¬ä¸€æ¬¡äº¤äº’è¢«æ”¾å…¥äº†ç¬¬äºŒæ¬¡äº¤äº’çš„æç¤ºä¸­ã€‚è¿™å°±æ˜¯è®°å¿†çš„ä½œç”¨ã€‚\n",
    "\n",
    "æœ‰è®¸å¤šä¸åŒçš„å¯¹è¯ç»“æ„æ–¹å¼ï¼Œè¯·æŸ¥çœ‹[æ–‡æ¡£](https://python.langchain.com/en/latest/use_cases/chatbots.html)ä¸­çš„ä¸åŒæ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»£ç†\n",
    "\n",
    "*[LangChain ä»£ç†æ–‡æ¡£](https://python.langchain.com/en/latest/modules/agents.html)*\n",
    "\n",
    "ä»£ç†æ˜¯LLMä¸­æœ€çƒ­é—¨çš„è¯é¢˜ä¹‹ä¸€ã€‚ä»£ç†æ˜¯å†³ç­–è€…ï¼Œå¯ä»¥æŸ¥çœ‹æ•°æ®ï¼Œæ¨ç†ä¸‹ä¸€æ­¥åº”è¯¥é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Œå¹¶é€šè¿‡å·¥å…·æ‰§è¡Œè¯¥è¡ŒåŠ¨ã€‚\n",
    "\n",
    "* **æ·±å…¥ç ”ç©¶** - [ä»£ç†ç®€ä»‹](https://youtu.be/2xxziIWmaSA?t=1972), [LangChain ä»£ç†ç½‘ç»œç ”è®¨ä¼š](https://www.crowdcast.io/c/46erbpbz609r)ï¼Œæ›´æ·±å…¥çš„ç ”ç©¶å³å°†æ¨å‡º\n",
    "* **ç¤ºä¾‹** - å¾…å®š\n",
    "* **ç”¨ä¾‹:** åœ¨æ— éœ€äººå·¥è¾“å…¥çš„æƒ…å†µä¸‹è‡ªä¸»è¿è¡Œç¨‹åº\n",
    "\n",
    "ä»£ç†çš„é«˜çº§ç”¨ä¾‹ç¤ºä¾‹å‡ºç°åœ¨[BabyAGI](https://github.com/yoheinakajima/babyagi)å’Œ[AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT)ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Agent imports\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import TextRequestsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘å°†è·å–è°·æ­Œæœç´¢ç»“æœã€‚å¦‚æœæ‚¨éœ€è¦ä¸€ä¸ªç ”ç©¶é¡¹ç›®çš„ç½‘ç«™åˆ—è¡¨ï¼Œæ‚¨å¯èƒ½ä¼šéœ€è¦è¿™æ ·åšã€‚\n",
    "\n",
    "æ‚¨å¯ä»¥åœ¨ä¸‹é¢çš„ç½‘å€æ³¨å†Œè¿™ä¸¤ä¸ªå¯†é’¥\n",
    "\n",
    "[GOOGLE_API_KEY](https://console.cloud.google.com/apis/credentials)\n",
    "[GOOGLE_CSE_ID](https://programmablesearchengine.google.com/controlpanel/create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID', 'YourAPIKeyIfNotSet')\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY', 'YourAPIKeyIfNotSet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆå§‹åŒ–æ‚¨å°†ä½¿ç”¨çš„ä¸¤ä¸ªå·¥å…·ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†æœç´¢è°·æ­Œï¼Œå¹¶è®©LLMèƒ½å¤Ÿæ‰§è¡ŒPythonä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n",
    "\n",
    "requests = TextRequestsWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†æ‚¨çš„ä¸¤ä¸ªå·¥å…·æ”¾å…¥å·¥å…·åŒ…ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Requests\",\n",
    "        func=requests.get,\n",
    "        description=\"Useful for when you to make a request to a URL\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€šè¿‡æä¾›å·¥å…·ã€LLMå’Œä»£ç†ç±»å‹æ¥åˆ›å»ºæ‚¨çš„ä»£ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨é—®å®ƒä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘å°†ç»™å‡ºä¸€ä¸ªåº”è¯¥è®©å®ƒå»è°·æ­Œæœç´¢çš„é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the capital of Canada is.\n",
      "Action: Search\n",
      "Action Input: \"capital of Canada\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLooking to build credit or earn rewards? Compare our rewards, Guaranteed secured and other Guaranteed credit cards. Canada's capital is Ottawa and its three largest metropolitan areas are Toronto, Montreal, and Vancouver. Canada. A vertical triband design (red, white, red)Â ... Browse available job openings at Capital One - CA. ... Together, we will build one of Canada's leading information-based technology companies â€“ join us,Â ... Ottawa is the capital city of Canada. It is located in the southern portion of the province of Ontario, at the confluence of the Ottawa River and the RideauÂ ... Shopify Capital offers small business funding in the form of merchant cash advances to eligible merchants in Canada. If you live in Canada and needÂ ... Download Capital One Canada and enjoy it on your iPhone, iPad and iPod touch. ... Simply use your existing Capital One online banking username and passwordÂ ... A leader in the alternative asset space, TPG was built for a distinctive approach, managing assets through a principled focus on innovation. We're Canada's largest credit union by membership because we prioritize people, not profits. Let's build the right plan to reach your financial goals, together. The national capital is Ottawa, Canada's fourth largest city. It lies some 250 miles (400 km) northeast of Toronto and 125 miles (200 km) west of Montreal,Â ... Finding Value Across the Capital Structure: Limited Recourse Capital Notes. Limited Recourse Capital Notes are an evolving segment of the Canadian fixed-incomeÂ ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Ottawa is the capital of Canada.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ottawa is the capital of Canada.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent({\"input\":\"What is the capital of canada?\"})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼Œé‚£æ˜¯æ­£ç¡®çš„ã€‚ç°åœ¨è®©æˆ‘ä»¬é—®ä¸€ä¸ªéœ€è¦åˆ—å‡ºå½“å‰ç›®å½•çš„é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the comments are about\n",
      "Action: Search\n",
      "Action Input: \"comments on https://news.ycombinator.com/item?id=34425779\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAbout a month after we started Y Combinator we came up with the phrase that ... Action Input: \"comments on https://news.ycombinator.com/item?id=34425779\" .\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the comments are about Y Combinator\n",
      "Final Answer: The comments on the webpage are about Y Combinator.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The comments on the webpage are about Y Combinator.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent({\"input\":\"Tell me what the comments are about on this webpage https://news.ycombinator.com/item?id=34425779\"})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»“æŸ\n",
    "\n",
    "å“‡ï¼æ‚¨ä¸€ç›´çœ‹åˆ°äº†æœ€åº•éƒ¨ã€‚\n",
    "\n",
    "æ¥ä¸‹æ¥è¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "äººå·¥æ™ºèƒ½çš„ä¸–ç•Œæ˜¯å·¨å¤§çš„ï¼Œç”¨ä¾‹å°†ç»§ç»­å¢é•¿ã€‚æˆ‘ä¸ªäººæœ€æœŸå¾…çš„æ˜¯æˆ‘ä»¬å°šä¸çŸ¥é“çš„ç”¨ä¾‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬è¿˜åº”è¯¥æ·»åŠ ä»€ä¹ˆåˆ°è¿™ä¸ªåˆ—è¡¨ä¸­ï¼Ÿ\n",
    "\n",
    "æŸ¥çœ‹è¿™ä¸ª[å­˜å‚¨åº“çš„è‡ªè¿°æ–‡ä»¶](https://github.com/gkamradt/langchain-tutorials)ä»¥è·å–æ›´å¤šçµæ„Ÿ\n",
    "åœ¨[YouTube](https://www.youtube.com/@DataIndependent)ä¸ŠæŸ¥çœ‹æ›´å¤šæ•™ç¨‹\n",
    "\n",
    "æˆ‘å¾ˆæƒ³çœ‹çœ‹æ‚¨å»ºç«‹çš„é¡¹ç›®ã€‚åœ¨[Twitter](https://twitter.com/GregKamradt)ä¸Š@æˆ‘ï¼\n",
    "\n",
    "å¦‚æœæ‚¨æœ‰æƒ³è¦ç¼–è¾‘çš„å†…å®¹ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„[è´¡çŒ®æŒ‡å—](https://github.com/gkamradt/langchain-tutorials)å¹¶æäº¤PR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
