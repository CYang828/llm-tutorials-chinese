{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKiW9QLJdYzI"
      },
      "source": [
        "# LlamaIndex基础知识\n",
        "\n",
        "在本课程中，我们将讨论LlamaIndex的基础知识及其核心组件\n",
        "\n",
        "本课程将讨论以下内容：\n",
        "\n",
        "1. 节点（Nodes）\n",
        "2. 文档加载器（Document loaders）\n",
        "3. 索引（Indexes）\n",
        "4. 检索器（Retrievers）\n",
        "5. 查询引擎（Query Engines）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXfewCv1eq4t"
      },
      "source": [
        "### 节点（Nodes）\n",
        "\n",
        "节点是LlamaIndex的基本单元。节点实际上就是一个包含一段文本的数据结构。\n",
        "\n",
        "每当您提供一个文档时，您可以将其拆分为多个块并存储在节点中。\n",
        "\n",
        "### 文档加载器（Document Loader）\n",
        "\n",
        "LlamaIndex中的文档加载器是一个用于从源中提取数据的接口。源可以是网页、YouTube视频、PDF等。\n",
        "\n",
        "LlamaIndex支持多种文档加载器，我们将研究其中一些以适应我们的用例。\n",
        "\n",
        "### 索引（Indexes）\n",
        "\n",
        "LlamaIndex中的索引是一种组织和存储来自各种数据源的信息的数据结构，使搜索变得更加容易。索引是建立在一组节点之上的。\n",
        "\n",
        "LlamaIndex提供了不同类型的索引，我们将在后续课程中学习。\n",
        "\n",
        "### 检索器（Retrievers）\n",
        "\n",
        "LlamaIndex中的检索器帮助根据给定的查询从索引中获取一组节点。它类似于一个搜索工具，从大型数据集中找到相关信息以回答您的问题。\n",
        "\n",
        "LlamaIndex中有不同类型的检索器，我们将在后续课程中学习。\n",
        "\n",
        "### 查询引擎（Query Engines）\n",
        "\n",
        "LlamaIndex中的查询引擎处理用户输入的查询，与底层数据结构（如索引）交互，并返回一个综合的响应。\n",
        "\n",
        "LlamaIndex提供了不同类型的查询引擎，我们将在后续课程中学习。\n",
        "\n",
        "让我们通过一个示例来理解所有这些概念。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkTzHRzAj-a4"
      },
      "source": [
        "### 安装LlamaIndex和依赖项\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGjuOcztdVdY"
      },
      "outputs": [],
      "source": [
        "!pip install llama_index langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7brjnBgakDxt"
      },
      "source": [
        "### 下载用于训练的数据。我们使用国情咨文文本文件来训练ChatGPT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N19pdxXakBf_"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\n",
        "!mkdir data\n",
        "!mv state_of_the_union.txt data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q1uZIhJkSCi"
      },
      "source": [
        "### 将输入文本加载到LlamaIndex输入中。我们可以使用一个简单的文档加载器来实现这一点，就像我们之前讨论过的那样。\n",
        "\n",
        "我们将使用SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wjCCvXkxkJjO"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader('./data').load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOwPvXrkrZ9"
      },
      "source": [
        "### 将数据拆分为节点。\n",
        "\n",
        "正如我们讨论过的，节点是保存输入的基本数据结构。我们将使用以下代码将上面加载的输入拆分为多个节点。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VSd_W7FXkmvi"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "parser = SimpleNodeParser()\n",
        "nodes = parser.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81GvDT90lHrZ"
      },
      "source": [
        "### 创建索引\n",
        "\n",
        "现在我们已经创建了节点，我们可以在其基础上创建一个索引。我们将使用VectorStoreIndex，它从节点中的所有文本创建嵌入并将其存储在向量数据库中。有关嵌入的更多细节将在第一课中分享。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qV8KYogxlD2I"
      },
      "outputs": [],
      "source": [
        "from llama_index import LLMPredictor, VectorStoreIndex\n",
        "from langchain import OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api-key\"\n",
        "\n",
        "index = VectorStoreIndex(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jxcV3s5oZGf"
      },
      "source": [
        "### 创建检索器\n",
        "\n",
        "我们将使用VectorIndexRetriever，根据相似性检索前k个匹配文档。在这个示例中，我们将保持k=2。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WTHjqs8pmbKm"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import VectorIndexRetriever\n",
        "\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G44xOu2pop2e"
      },
      "source": [
        "### 创建查询引擎\n",
        "\n",
        "现在我们可以在检索器上构建一个查询引擎，开始进行查询。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rsXYrMTTosPT"
      },
      "outputs": [],
      "source": [
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZNWum3o5Rz"
      },
      "source": [
        "### 现在进行一个查询"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzA8F5d1o7Ss",
        "outputId": "4fe4fc93-e62b-4b73-c52b-6fc5e93496d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The author grew up in a family where they had to adjust to the rising cost of food, gas, housing, and other expenses. They experienced the struggles of their father leaving home to find work.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP4BaEr/v1gFjHe9TUouSak",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
