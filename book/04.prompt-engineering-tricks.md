# 提示技巧

在本指南中，我们将介绍一些高级和有趣的方法，利用提示工程来执行有用和更高级的任务。


## 生成数据
LLMs具有生成连贯文本的强大能力。使用有效的提示策略可以引导模型产生更好、更一致和更真实的响应。LLMs还可以特别有用地生成数据，这对于运行各种实验和评估非常有用。例如，我们可以使用它来为情感分类器生成快速样本，如下所示：

*提示：*
```
生成10个情感分析的范例。示例被归类为正面或负面。生成2个负面示例和8个正面示例。使用以下格式的示例：
Q：<句子>
A：<情感>
```

*输出：*
```
Q:我刚刚得到了最好的消息！
A:正面

Q:我们刚刚在工作中得到了加薪！
A:正面

Q:我为今天所取得的成就感到非常自豪。
A:正面

Q:我度过了最美好的一天！
A:正面

Q:我真的很期待周末。
A:正面

Q:我刚刚得到了最好的礼物！
A:正面

Q:我现在感到非常快乐。
A:正面

Q:我很幸运有这么棒的家人。
A:正面

Q:外面的天气很阴沉。
A:负面

Q:我刚刚得到了一些可怕的消息。
A:负面
```

这非常有用。我们实际上在指南的另一个部分中使用了这个示例进行不同的测试。


## 代码生成

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import CODE1 from '../../img/code-generation/chat-mode.png'

<Callout emoji="⚠️">
  这个小节这在开发当中
</Callout>

像ChatGPT这种大语言模型对于生成代码是非常擅长的。在本节中，我们将给出一些示例来介绍如何使用ChatGPT进行代码生成：

以下所有示例均使用OpenAI的Playground（聊天模式）和`gpt-3.5-turbo`模型。

与OpenAI的所有聊天模型一样，您可以使用`系统消息`来定义响应的行为和格式。我们将使用以下系统消息作为提示示例：

```
您是一位有用的代码助手，可以教初级开发人员如何编写代码。您选择的语言是Python。不解释代码，只生成代码块。
```

### 基础例子

`用户消息`将是提示本身，其中包含了您希望模型生成的特定代码的指令。下面是代码生成的第一个基本提示快照。请注意，最终代码是由`助手`生成的。

<Screenshot src={CODE1} alt="CODE1" />

如果您想自己试试，这是一些提示： 

```
写一段代码询问用户他们的名字并向他们说Hello
```

### 将注释转换成代码

你还可以使用这些大模型预言代码的代码生成功能将注释转换成代码。让我们看另一个已注释块作为指令的示例：

*提示：*
```
"""
1. 创建一个电影名称列表
2. 创建这些电影的评分列表
3. 组合他们并创建一个包含10部电影及其评级的json对象
"""
```

*输出：*
```python
movies = ["The Shawshank Redemption", "The Godfather", "The Dark Knight", "Schindler's List", "Pulp Fiction", "The Lord of the Rings: The Return of the King", "Forrest Gump", "Star Wars: Episode V - The Empire Strikes Back", "Inception", "The Silence of the Lambs"]

ratings = [9.3, 9.2, 9.0, 8.9, 8.9, 8.9, 8.8, 8.7, 8.7, 8.6]

movie_ratings = {}

for i in range(len(movies)):
    movie_ratings[movies[i]] = ratings[i]

json_object = json.dumps(movie_ratings, indent=4)

print(json_object)
```

生成的代码看起来是可以正常运行的代码。但是，输出的代码不包含重要的`import`语句，即：`import json`。当这些模型生成可运行代码时，您必须关注这样的小细节，并始终确保测试您的代码。 

### 完成功能或继续下一行

这些大语言模型也被整合到Github Copilot等工具中，这使得它们对开发人员很有用。其中一个很有用的功能是通过模型来完成函数的功能。 

*提示：*
```python
# 将两个数字相乘并加75的函数

def multiply(
```

*Output:*
```python
a, b):
    result = a * b
    result += 75
    return result
```

### MySQL查询语句生成

除了上面的基本代码生成示例外，您还可以使用该模型生成其他有用的代码，例如创建和测试MySQL查询。 

假设您有一个数据集，其中包含一些信息，您可以将其作为提示的一部分包含在内，然后指示它生成特定查询。例如：

```
"""
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Create a MySQL query for all students in the Computer Science department
"""
```

*输出：*
```mysql
SELECT students.StudentId, students.StudentName
FROM students
INNER JOIN departments
ON students.DepartmentId = departments.DepartmentId
WHERE departments.DepartmentName = 'Computer Science';
```

模型生成了一个查询语句！但是，我们没有对应的数据库来测试生成的查询语句是否正确。如果要测试，则需要创建这个数据库。幸运地是，您可以使用ChatGPT为您生成此内容。例如使用上述提示的修改版本，其指令略有不同，以生成数据库结构：

```mysql
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Create a valid database schema with the above tables and columns
```

模型生成了以下的数据表创建语句：

```mysql
CREATE TABLE departments (
  DepartmentId INT PRIMARY KEY,
  DepartmentName VARCHAR(50)
);

CREATE TABLE students (
  DepartmentId INT,
  StudentId INT PRIMARY KEY,
  StudentName VARCHAR(50),
  FOREIGN KEY (DepartmentId) REFERENCES departments(DepartmentId)
);
```

您也可以创建一个临时的数据库，使用类似[sqliteonline.com](https://sqliteonline.com/)。

您还需要虚拟数据来测试生成的查询是否有效。让我们也使用ChatGPT！提示语句类似下例：

```mysql
CREATE TABLE departments (
  DepartmentId INT PRIMARY KEY,
  DepartmentName VARCHAR(50)
);

CREATE TABLE students (
  DepartmentId INT,
  StudentId INT PRIMARY KEY,
  StudentName VARCHAR(50),
  FOREIGN KEY (DepartmentId) REFERENCES departments(DepartmentId)
);

给定上面的数据表结构，生成有效的插入语句，每个表包含4行：
```

带有插入语句的输出：

```mysql
INSERT INTO departments (DepartmentId, DepartmentName)
VALUES (1, 'Computer Science'), (2, 'Mathematics'), (3, 'Physics'), (4, 'Biology');

INSERT INTO students (DepartmentId, StudentId, StudentName)
VALUES (1, 101, 'John Doe'), (1, 102, 'Jane Doe'), (2, 201, 'Alice Smith'), (2, 202, 'Bob Johnson');
```

现在您已经有了数据库和虚拟数据，可以测试原始查询了。根据虚拟数据，结果应该是两行，分别包含`Jane Doe`和`John Doe`。

### 解释代码
如果您正在学习使用某种语言编程，提示模型解释某些代码位可能会很有用。让我们重用上面生成的查询，并要求模型对其进行解释。

如果您使用的是与之前相同的`系统消息`，请注意如何指导模型。例如，如果我们使用以下示例，模型会抱怨它是 Python 中的代码助手，但它仍然提供了解释。有时，模型拒绝生成您指示的内容，因为它旨在遵循系统消息。

*提示：*

```mysql
SELECT students.StudentId, students.StudentName
FROM students
INNER JOIN departments
ON students.DepartmentId = departments.DepartmentId
WHERE departments.DepartmentName = 'Computer Science';

解释上面的SQL语句。
```

*输出：*

```
对不起，作为一个Python代码助手，我不能生成SQL语句。但是，我能解释您提供的SQL语句的含义。 

这个SQL语句从`students`表选择了`StudentId`和`StudentName`列，其中`departments`表中的`DepartmentName`列等于'Computer Science'。为了实现这一效果，语句使用一个内部连接关键字在`DepartmentId`列和`students`和`departments`表。 

简单来说，语句选择了计算机科学系注册的学生的姓名和ID。
```

### 编辑代码
例子很快就来！

### 调试代码
例子很快就来！

### 最佳实践
很快就来！


## 毕业生职位分类案例研究

Clavié等人(2023)提供了一项关于提示工程应用于生产系统中中等规模文本分类用例的案例研究。通过使用将工作分类为真正的“初级职位”(是否适合应届毕业生的任务)，他们评估了一系列提示工程技术，并使用GPT-3.5 (gpt-3.5-turbo)报告了他们的结果。

该研究表明，LLMs在所有经过测试的模型中表现最佳，包括DeBERTa-V3中的一个极强的基准模型。gpt-3.5-turbo在所有关键指标上也明显优于早期的GPT3变体，但需要进行额外的输出解析，因为其遵循模板的能力似乎不如其他变体。

他们的提示工程方法的关键发现是：

- 对于像这样不需要专业知识的任务，Few-shot CoT提示在所有实验中的表现都不如Zero-shot提示。
- 提示对于引导正确推理的影响非常巨大。简单地要求模型对给定的工作进行分类会得到65.6的F1分数，而后提示工程模型的F1分数为91.7。
- 试图强制模型遵循模板会降低所有情况下的性能（这种行为在GPT-4的早期测试中消失，这项测试在该论文之后进行）。
- 许多小的修改对性能产生了巨大的影响。
  - 下面的表格显示了所有经过测试的修改。
  - 正确地给出指令并重复关键点似乎是最有效的提升性能的方法。
  - 简单地给模型一个(人类的)名字并这样称呼它，可以将F1分数提高0.6个百分点。

### 经本文测试的 Prompt策略

| Short name | Description                                                                |
|------------|----------------------------------------------------------------------------|
| Baseline   | 提供一个职位招聘信息并询问它是否适合毕业生。          |
| CoT        | 在查询之前给出几个准确分类的示例。       |
| Zero-CoT   | 要求模型一步步推理后再给出答案。      |
| rawinst    | 通过添加到用户消息中, 来给出有关其角色和任务的说明。   |
| sysinst    | 作为系统消息给出有关其角色和任务的说明。           |
| bothinst   | 将角色作为系统消息和任务作为用户消息拆分说明。       |
| mock       | 通过模拟讨论来给出任务说明，其中模型确认了它们。 |
| reit       | 通过重复强调关键要素来加强说明。              |
| strict     | 要求模型严格按照给定模板回答。         |
| loose      |  要求仅根据给定模板给出最终答案。       |
| right      | 要求模型得出正确的结论。                              |
| info       |提供额外的信息以解决常见的推理失败。       |
| name       |  为模型取一个我们在对话中称呼它的名称。              |
| pos        | 在查询之前向模型提供正面反馈。              |

### 所有Prompt性能策略对性能的影响

|                                        | Precision     | Recall        | F1            | Template Stickiness    |
|----------------------------------------|---------------|---------------|---------------|------------------------|
| _Baseline_                             | _61.2_        | _70.6_        | _65.6_        | _79%_                  |
| _CoT_                                  | _72.6_        | _85.1_        | _78.4_        | _87%_                  |
| _Zero-CoT_                             | _75.5_        | _88.3_        | _81.4_        | _65%_                  |
| _+rawinst_                             | _80_          | _92.4_        | _85.8_        | _68%_                  |
| _+sysinst_                             | _77.7_        | _90.9_        | _83.8_        | _69%_                  |
| _+bothinst_                            | _81.9_        | _93.9_        | _87.5_        | _71%_                  |
| +bothinst+mock                         | 83.3          | 95.1          | 88.8          | 74%                    |
| +bothinst+mock+reit                    | 83.8          | 95.5          | 89.3          | 75%                    |
| _+bothinst+mock+reit+strict_           | _79.9_        | _93.7_        | _86.3_        | _**98%**_              |
| _+bothinst+mock+reit+loose_            | _80.5_        | _94.8_        | _87.1_        | _95%_                  |
| +bothinst+mock+reit+right              | 84            | 95.9          | 89.6          | 77%                    |
| +bothinst+mock+reit+right+info         | 84.9          | 96.5          | 90.3          | 77%                    |
| +bothinst+mock+reit+right+info+name    | 85.7          | 96.8          | 90.9          | 79%                    |
| +bothinst+mock+reit+right+info+name+pos| **86.9**      | **97**        | **91.7**      | 81%                    |

“Template stickiness” 指的是模型多频繁地按照所期望的格式作答。


## 在LLM中调用函数

### 调用函数

函数调用是指可靠地连接LLM与外部工具的能力。让用户能够使用高效的外部工具、与外部API进行交互。

GPT-4和GPT-3.5是经过微调的LLM，能够检测函数是否被调用，随后输出包含调用函数参数的JSON。通过这一过程被调用的函数能够作为工具添加到您的AI应用中，并且您可以在单个请求中定义多个函数。

函数调用是一项重要能力。它对于构建LLM驱动的聊天机器人或代理至关重要。这些聊天机器人或代理需要为LLM检索上下文。它们还与外部工具交互。这种交互是通过将自然语言转换为API调用来完成的。

函数调用使开发者能够创建：

- 能够高效使用外部工具回答问题的对话代理。例如，查询“伯利兹的天气如何？”将被转换为类似`get_current_weather(location: string, unit: 'celsius' | 'fahrenheit')`的函数调用
- 用于提取和标记数据的LLM驱动解决方案（例如，从维基百科文章中提取人名）
- 可以帮助将自然语言转换为API调用或有效数据库查询的应用程序
- 能够与知识库交互的对话式知识检索引擎

在这份指南中，我们展示了如何针对GPT-4和其他开源模型给出提示，以执行不同的函数调用。

### 使用GPT-4进行函数调用

作为一个基本示例，假设我们要求模型检查特定地点的天气。

LLM本身无法响应此请求。因为它所使用的训练数据集截止至之前的某个日期。解决这个问题的方法是将LLM与外部工具结合起来。您可以利用模型的函数调用能力来确定要调用的外部函数及其参数，然后让它返回最终回复结果。以下是一个简单的示例，展示了如何使用OpenAI API实现这一点。

假设一个用户向模型提出以下问题：

```
伦敦的天气如何？
```

要使用函数调用处理此请求，第一步是定义一个或一组天气函数。您将作为OpenAI API请求的一部分传递这些函数：

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "unit": {
                        "type": "string", 
                        "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["location"],
            },
        },   
    }
]
```

`get_current_weather`函数能够返回指定位置的天气情况。当您将这个函数定义作为请求的一部分传递时，它实际上并不执行函数，只是返回一个包含调用函数所需参数的JSON对象。以下是一些如何实现这一点的代码片段。

您可以如下定义一个完整的函数：

```python
def get_completion(messages, model="gpt-3.5-turbo-1106", temperature=0, max_tokens=300, tools=None):
    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        tools=tools
    )
    return response.choices[0].message
```

您可以像这样构造用户提问：
```python
messages = [
    {
        "role": "user",
        "content": "伦敦的天气如何？"
    }
]
```

最后，您可以调用`get_completion`函数，将结果传递给`response`中的`messages`和`tools`：

```python
response = get_completion(messages, tools=tools)
```

`response`的构造如下所示：

```python
ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='...', function=Function(arguments='{"location":"London","unit":"celsius"}', name='get_current_weather'), type='function')])
```

特别地，`arguments` 对象包含了模型提取的重要参数，这些参数将被用于完成请求。

然后您可以调用一个外部天气API来获取实际的天气信息。一旦您有了天气信息，就可以将其传回模型，随后根据原始用户问题总结出最终回应。

这里有一个[python notebook](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-function-calling.ipynb)，它提供了一个简单示例，展示了如何使用OpenAI API进行函数调用。

### 使用开源LLM进行函数调用
更多使用开源LLM进行函数调用的说明即将推出...

### 函数调用用例
更多函数调用用例即将推出...


## Tackling Generated Datasets Diversity

import {Screenshot} from 'components/screenshot'

import IMG1 from '../../img/synthetic_diversity/textbooks_1.png'
import IMG2 from '../../img/synthetic_diversity/textbooks_2.png'

In the previous [chapter](https://www.promptingguide.ai/applications/synthetic_rag), we discussed the potential of using LLM for synthetic dataset generation to further finetune a local Retriever model. This method is possible due to the availability of a large corpus of unlabeled documents. Each document is used to generate one or more synthetic queries and form a query-document pair.

But what if Information Retrieval is not your task? Let's say you are working on a legal document classification problem but are not permitted to send any data to an external API. In this situation, you would need to train a local model. However, collecting data could become a significant obstacle, causing delays in product development.

For simplicity, let’s suppose the goal is to generate children's stories. This task was the starting point for research by [Eldan et al. (2023)](https://arxiv.org/abs/2305.07759). Each story consists of 2-3 paragraphs that follow a straightforward plot and theme, while the entire dataset covers a child's vocabulary and factual knowledge.

Language is not just a system of rules and symbols; it conveys and interprets meaning. The main challenge of using large language models to produce training data is ensuring dataset diversity. Even with high [generation temperature](https://www.promptingguide.ai/introduction/settings), models can produce repetitive datasets lacking the necessary diversity (even for a child's language). Coherence and relevance are other natural language generation challenges.

To tackle the diversity issue, the authors prepared a vocabulary of around 1500 basic words, mirroring a typical child's vocabulary, divided into nouns, verbs, and adjectives. In each generation, one verb, one noun, and one adjective were randomly selected. The model then generates a story integrating these random words.

This technique significantly broadened the dataset's diversity, ensuring stories cover a child's entire vocabulary and diverse concept combinations. Additionally, the authors integrated potential story features (like dialogue, plot twists, bad endings, or moral lessons). A random subset of these features was chosen for each story, and the model was prompted to include them.

*Prompt:*
```
Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”{random.choice(verbs_list)}”, the noun ”{random.choice(nouns_list)}” and the adjective ”{random.choice(adjectives_list)}”. The story should have the following features: {random.choice(features_list)}, {random.choice(features_list)}. Remember to only use simple words!
```

Let's assume the gaps were filled as follows:

*Prompt:*
```
Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would likely understand. The story should use the verb ”decorate”, the noun ”thunder” and the adjective ”ancient”. The story should have the following features: the story should contain at least one dialogue, the story has a bad ending. Remember to only use simple words!
```

*Output:*
```
Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. One day, she found a big box in the attic. She opened it and saw many shiny decorations. Lily was very happy and decided to use them in her room. As Lily was decorating her room, the sky outside became dark. There was a loud thunder sound, and Lily got scared. She ran to her mom and said, ”Mommy, the thunder is so loud!” Her mom hugged her and said, ”Don’t worry, it will pass soon.” But the thunder did not stop. It got louder and louder, and the ancient house started to shake. Suddenly, the roof fell down on the pretty decorations. Lily was sad because her room was not pretty anymore. The end.
```

Here we rely on the latest text generation models (GPT-3.5 and GPT-4), which can produce vast amounts of synthetic content, following the instructions. Since we formulate the prompt randomly each time, and the model adheres to it precisely, the stories turn out to be incredibly varied. The narrative will be entirely different even if one or two words remain the same. In essence, we apply this technique to inject randomness into the prompt, generating a diverse dataset.

You get the idea:

1. Identify which parameters/entities might vary between different samples in your synthetic dataset;
2. Generate or manually compile a collection of these entities to fill in the gaps;
3. Produce the dataset by randomly selecting entities for insertion. It's best to set the generation temperature higher than the default but below the maximum;
4. Train a local model on the generation results of ChatGPT/GPT-4.

It is important to note that one of the entities used to seed your generation could be a class label. For example, in the sentiment classification task, you can directly mention "positive" or "negative" in the prompt to receive a generated text with the corresponding label. Then, a local classifier is trained on this data.

### Iterative (Hierarchical) Synthetic Data Generation

The format can be made more complex by using even more entities, some of which are generated beforehand by the LLM itself. For example, one could start with a request to generate a story summary and pen down one sentence that must appear in the story. Later, just use that generated intermediate data in the final request.

*Prompt:*
```
Summary: {a short summary generated by LLM, using the approach above}
Features: {copy the features from the initial prompt}
Sentence: {a sentence generated by LLM, which should be present in the story}
Words: {copy the words from the initial prompt}
Story:
```

Example of a filled-in prompt:

*Prompt:*
```
Summary: Lily and Timmy build a sandcastle together and learn to compromise, but it gets knocked over by a gust of wind. They find beauty in the broken sandcastle and play happily with a butterfly.
Features: Dialogue, Foreshadowing, Twist
Sentence: One day, she went to the park and saw a beautiful butterfly.
Words: disagree, network, beautiful
Story:
```

*Output:*
```
Once upon a time, there was a little girl named Lily. She loved to play with her toys and her friends. One day, she went to the park and saw a beautiful butterfly. She tried to catch it, but it flew away. Lily’s friend, Timmy, came to play with her. They decided to build a sandcastle, but they disagreed on how to build it. Lily wanted to make it tall, while Timmy wanted to make it wide. They argued for a while, but finally agreed to make it both tall and wide. As they were building the sandcastle, they noticed a group of ants working together. They realized that the ants were building a network of tunnels. Suddenly, a gust of wind came and knocked over their sandcastle. They were sad, but then they saw the butterfly again. It landed on the remains of their sandcastle and they realized that it was still beautiful, even in its broken state. They smiled and played together happily.
```

Thus, it's possible to generate hundreds of thousands of very diverse examples to train the model on. Let's say you need to train a classifier that determines whether a text contains a dialogue or a plot twist. As the initial prompt contains labels, it's known which target value needs to be predicted for each generated sample.

### Textbooks Are All You Need

A crucial question arising from this approach is whether the synthesis of a dataset can truly provide benefits when training networks for real-world applications. Fortunately, the authors addressed this question by conducting their investigation and validating the efficacy of training smaller language models using synthetic data derived from State-of-the-Art LLMs.

In their study, [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644) emphasize the importance of high-quality training data in their model. They argue that language models would be more effective if they were trained on materials that resemble the characteristics of a well-regarded "textbook": clear, comprehensive, informative, and unbiased.

These principles formed the basis for creating a semi-synthetic dataset to train LLM called Phi-1. The main evaluation task is to generate a Python function that follows a given text description or docstring. The model's quality is evaluated using the HumanEval benchmark ([Chen et al., 2021](https://arxiv.org/abs/2107.03374)).

The authors highlight the importance of diversity in this approach for several reasons. It exposes the language model to a variety of coding expressions and problem-solving approaches, reduces the risk of overfitting or relying on specific patterns, and improves the model's ability to handle unfamiliar or innovative tasks.

To address the code-writing challenge, the authors created textbook-like documents that focus on topics promoting reasoning and basic algorithmic skills. They achieved diversity by imposing restrictions on:

- topics
- target audience

Unfortunately, the authors did not provide specific information about the prompt template used to generate the synthetic data. However, they did demonstrate the resulting output. They chose to use ChatGPT (GPT-3.5) instead of GPT-4, and even this strategy yielded excellent results as they fine-tuned the model using synthetic data.

<Screenshot src={IMG1} alt="Generated textbook-like sample" />

Image Source: [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)

It's essential to pay attention to the target audience constraint. Designating a target audience is an excellent way to enhance synthetic data diversity. A high school student, a CS undergraduate, and a PhD candidate certainly phrase their explanations and process information differently, making the generated data even more varied. Let's attempt to recreate the prompt.


*Prompt:*
```
Write an extract from a Computer Science textbook for a 1st-year bachelor. The coding language is Python 3.6.

This is an extract from the middle of the following topic: Singular matrices.

The extract starts with a high-level overview of the topic. Then, it presents an example and describes the solution in natural language. After that, it provides 1-2 code snippets, following the example. Each snippet has no more than 10 rows. There should be no text after code snippets.

Keep in mind that the extract should be concise and explain only one concept at a time.  The code should represent a Python function & its call. All the common ML/DS libraries are available.

Don't be too verbose. The expected length of the extract is 2 paragraphs at most.
```

*Output:*
```
**Singular Matrices**

In linear algebra, a matrix is termed as "singular" if it doesn't have an inverse. Another equivalent definition is when the determinant of the matrix is zero. Singular matrices are crucial because they represent systems of linear equations that do not have a unique solution.

Consider a 2x2 matrix `[[a, b], [c, d]]`. If the product of `ad` and `bc` is the same (i.e., `ad = bc`), then this matrix is singular. Let's explore this with an example: given the matrix `[[2, 4], [1, 2]]`, you'll find that the product of the diagonals yields the same result (2 * 2 = 4 * 1), thus it's a singular matrix.

import numpy as np

def is_singular(matrix):
    determinant = np.linalg.det(matrix)
    return abs(determinant) < 1e-9

matrix_example = np.array([[2, 4], [1, 2]])
print(is_singular(matrix_example))  # returns True
```

Quite close!

In total, the authors generated 1B tokens to augment the model's training set, allowing a smaller model (only 1.5B parameters) to rival models ten times its size (for details, refer to the article [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)).

<Screenshot src={IMG2} alt="Phi-1 metrics, compared to bigger models." />

Image Source: [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)

For your task, you probably don't need such a large amount of synthetic data (since the authors studied the pretraining, which requires significant resources). However, even as an estimate, at a price of `$0.002` per 1k tokens (standard ChatGPT pricing), it would cost `$2000` for the generated tokens and approximately the same amount for the prompts.

Keep in mind that fine-tuning on synthetic data becomes more valuable as the domain becomes more niche, especially if the language deviates from English (among other factors). Additionally, this method works well with [Chain-of-Thought (CoT)](https://www.promptingguide.ai/techniques/cot), helping the local model improve its reasoning capabilities. Other prompting techniques work, too. And don't forget that open-source models like Alpaca ([Taori et al., (2023)](https://crfm.stanford.edu/2023/03/13/alpaca.html)) and Vicuna ([Zheng et al., (2023)](https://lmsys.org/blog/2023-03-30-vicuna/)) excel through fine-tuning on synthetic data.


## Generating Synthetic Dataset for RAG

import {Screenshot} from 'components/screenshot'
import remarkMath from 'remark-math'
import rehypeKatex from 'rehype-katex'

import IMG1 from '../../img/synthetic_rag/synthetic_rag_1.png'
import IMG2 from '../../img/synthetic_rag/synthetic_rag_2.png'
import IMG3 from '../../img/synthetic_rag/synthetic_rag_3.png'
import IMG4 from '../../img/synthetic_rag/synthetic_rag_4.png'


### Synthetic Data for RAG Setup
Unfortunately, in the life of a Machine Learning Engineer, there's often a lack of labeled data or very little of it. Typically, upon realizing this, projects embark on a lengthy process of data collection and labeling. Only after a couple of months can one start developing a solution.

However, with the advent of LLM, the paradigm shifted in some products: now one can rely on LLM’s generalization ability and test an idea or develop an AI-powered feature almost immediately. If it turns out to work (almost) as intended, then the traditional development process can begin.

<Screenshot src={IMG1} alt="Paradigm shift in AI-powered products." />

Image Source: [The Rise of the AI Engineer, by S. Wang](https://www.latent.space/p/ai-engineer)

One of the emerging approaches is [Retrieval Augmented Generation (RAG)](https://www.promptingguide.ai/techniques/rag). It's used for knowledge-intensive tasks where you can't solely rely on the model's knowledge. RAG combines an information retrieval component with a text generator model. To learn more about this approach, refer to [the relevant section in the guide](https://www.promptingguide.ai/techniques/rag).

The key component of RAG is a Retrieval model that identifies relevant documents and passes them to LLM for further processing. The better the performance of the Retrieval model, the better the product or feature outcome. Ideally, Retrieval works well right out of the box. However, its performance often drops in different languages or specific domains.

Imagine this: you need to create a chatbot answering questions based on Czech laws and legal practices (in Czech, of course). Or design a tax assistant (a use case presented by OpenAI during the GPT-4 presentation) tailored for the Indian market. You'll likely find that the Retrieval model often misses the most relevant documents and doesn't perform as well overall, thus limiting the system's quality.

But there's a solution. An emerging trend involves using existing LLMs to synthesize data for the training of new generations of LLMs/Retrievers/other models. This process can be viewed as distilling LLMs into standard-sized encoders via prompt-based query generation. While the distillation is computationally intensive, it substantially reduces inference costs and might greatly enhance performance, particularly in low-resource languages or specialized domains.

In this guide, we will rely on the latest text generation models, like ChatGPT and GPT-4, which can produce vast amounts of synthetic content following instructions. [Dai et al. (2022)](https://arxiv.org/abs/2209.11755) proposed a method where with only 8 manually labeled examples and a large corpus of unlabeled data (documents for retrieval, e.g., all the parsed laws), one can achieve a near State-of-the-Art performance. This research confirms that synthetically generated data facilitates training task-specific retrievers for tasks where supervised in-domain fine-tuning is a challenge due to data scarcity.

### Domain-Specific Dataset Generation
To utilize LLM, one needs to provide a short description and manually label a few examples. It's important to note that different retrieval tasks possess varying search intents, meaning different definitions of "relevance." In other words, for the same pair of (Query, Document), their relevance might differ entirely based on the search intent. For instance, an argument retrieval task might seek supporting arguments, while other tasks require counter-arguments (as seen in [ArguAna dataset](https://aclanthology.org/P18-1023/)).

Consider the example below. Though written in English for easier understanding, remember that data can be in any language since ChatGPT/GPT-4 efficiently processes even low-resource languages.

*Prompt:*
```
Task: Identify a counter-argument for the given argument.

Argument #1: {insert passage X1 here}

A concise counter-argument query related to the argument #1: {insert manually prepared query Y1 here}

Argument #2: {insert passage X2 here}
A concise counter-argument query related to the argument #2: {insert manually prepared query Y2 here}

<- paste your examples here ->

Argument N: Even if a fine is made proportional to income, you will not get the equality of impact you desire. This is because the impact is not proportional simply to income, but must take into account a number of other factors. For example, someone supporting a family will face a greater impact than someone who is not, because they have a smaller disposable income. Further, a fine based on income ignores overall wealth (i.e. how much money someone actually has: someone might have a lot of assets but not have a high income). The proposition does not cater for these inequalities, which may well have a much greater skewing effect, and therefore the argument is being applied inconsistently.

A concise counter-argument query related to the argument #N:
```

*Output:*
```
punishment house would make fines relative income
```

In general, such a prompt can be expressed as:

$(e_{prompt}, e_{doc}(d_{1}), e_{query}(q_1), . . . , e_{doc}(d_k), e_{query}(q_k), e_{doc}(d))$

, where $e_{doc}$ and $e_{query}$ are task-specific document, query descriptions respectively, $e_{prompt}$ is a task-specific prompt/instruction for ChatGPT/GPT-4, and $d$ is a new document, for which LLM will generate a query.

From this prompt, only the last document $d$ and the generated query will be used for further training of the local model. This approach can be applied when a target retrieval corpus $D$ is available, but the number of annotated query-document pairs for the new task is limited.

The whole pipeline overview: 

<Screenshot src={IMG2} alt="PROMPTGATOR Dataset Generation & Training Overview." />

Image Source: [Dai et al. (2022)](https://arxiv.org/abs/2209.11755)

It's crucial to handle manual annotation of examples responsibly. It's better to prepare more (for instance, 20), and randomly pick 2-8 of them to the prompt. This increases the diversity of generated data without significant time costs in annotation. However, these examples should be representative, correctly formatted, and even detail specifics such as the target query length or its tone. The more precise the examples and instructions, the better the synthetic data will be for training Retriever. Low-quality few-shot examples can negatively impact the resulting quality of the trained model.

In most cases, using a more affordable model like ChatGPT is sufficient, as it performs well with unusual domains and languages other than English. Let's say, a prompt with instructions and 4-5 examples typically takes up 700 tokens (assuming each passage is no longer than 128 tokens due to Retriever constraints) and generation is 25 tokens. Thus, generating a synthetic dataset for a corpus of 50,000 documents for local model fine-tuning would cost: `50,000 * (700 * 0.001 * $0.0015 + 25 * 0.001 * $0.002) = 55`, where `$0.0015` and `$0.002` are the cost per 1,000 tokens in the GPT-3.5 Turbo API. It's even possible to generate 2-4 query examples for the same document. However, often the benefits of further training are worth it, especially if you're using Retriever not for a general domain (like news retrieval in English) but for a specific one (like Czech laws, as mentioned).

The figure of 50,000 isn't random. In the research by [Dai et al. (2022)](https://arxiv.org/abs/2209.11755), it's stated that this is approximately the number of manually labeled data needed for a model to match the quality of one trained on synthetic data. Imagine having to gather at least 10,000 examples before launching your product! It would take no less than a month, and the labor costs would surely exceed a thousand dollars, much more than generating synthetic data and training a local Retriever Model. Now, with the technique you learned today, you can achieve double-digit metric growth in just a couple of days!

<Screenshot src={IMG3} alt="Synthetic Dataset VS Manually Labeled Dataset" />

Image Source: [Dai et al. (2022)](https://arxiv.org/abs/2209.11755)

And here are prompt templates from the same paper for some of the datasets in BeIR benchmark.

<Screenshot src={IMG4} alt="Prompt Templates from PROMPTGATOR paper." />

Image Source: [Dai et al. (2022)](https://arxiv.org/abs/2209.11755)


