# 提示工程

这里提供两套学习教程，一套为简单版，掌握简单版能够能够帮助你释放80%的大模型能力，满足基础的实用；但是如果你想追求卓越，并且你希望大模型能够做很多复杂的事情，那就需要学习高级版，这可能需要你花费一些时间。

## 简单版（80%能力释放）
把你的问题，按照下面七个步骤进行描述。

- （1）确定问题的核心（核心）：首先明确问题的关键点，包括你想要解决的具体问题和期望达到的目标。
- （2）分解问题（详细）：将问题拆分成更小、更易于管理的部分。这有助于更清楚地了解问题的各个方面，以及它们之间的关系。
- （3）提供背景信息（背景）：给出与问题相关的背景信息和上下文，这有助于ChatGPT更好地理解问题的实际环境和需求。
- （4）设定优先级（优先级）：确定问题中各部分的优先级，以便ChatGT能够根据你的需求和关注点提供针对性的回答。
- （5）提出具体问题（具体）：在描述问题的过程中，尽量使用明确、具体的语言。避免使用模糊或多义词汇，以减少歧义和误解的可能性。
- （6）陈述假设或限制条件（限制）：如果问题涉及特定的假设或限制条件，请明确地表达出来。这将有助于ChatGPT提供更贴近实际需求的解决方案。
- （7）指定期望的输出格式（输出）：明确表述你希望得到的答案形式，例如列表、段落、图表等。这可以帮助ChatGPT更好地满足你的期望。

下面是一个详细的例子，可供参考。

|#|关键词|问题|
|:----|:----|:----|
|1|核心|我要创建一个简单的Python程序,用于计算两个数字的和|
|2|详细|将问题分为两部分:1)输入两个数字; 2)计算它们的和|
|3|背景|我正在学习Python编程,对于这个任务,我只需要一个简单的解决方案,不涉及复杂的功能|
|4|优先级|首先,我需要知道如何获取用户输入的两个数字；其次,我需要知道如何计算这两个数字的和|
|5|具体|如何使用Python获取两个用户输入的整数,并计算它们的和|
|6|限制|我希望使用Python的基本功能,不使用任何外部库或模块|
|7|输出|请以代码示例的形式提供答案|

## 高级版（100%+能力释放）

提示工程（Prompt Engineering）是一门较新的学科，关注提示词开发和优化，帮助用户将大语言模型（Large Language Model, LLM）用于各场景和研究领域。 掌握了提示工程相关技能将有助于用户更好地了解大型语言模型的能力和局限性。

研究人员可利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。开发人员可通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。

提示工程不仅仅是关于设计和研发提示词。它包含了与大语言模型交互和研发的各种技能和技术。提示工程在实现和大语言模型交互、对接，以及理解大语言模型能力方面都起着重要作用。用户可以通过提示工程来提高大语言模型的安全性，也可以赋能大语言模型，比如借助专业领域知识和外部工具来增强大语言模型能力。

## 模型设置

使用提示词时，您会通过 API 或直接与大语言模型进行交互。你可以通过配置一些参数以获得不同的提示结果。

**Temperature：** 简单来说，temperature 的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。我们目前也在增加其他可能 token 的权重。在实际应用方面，对于质量保障（QA）等任务，我们可以设置更低的 temperature 值，以促使模型基于事实返回更真实和简洁的结果。 对于诗歌生成或其他创造性任务，你可以适当调高 temperature 参数值。

**Top_p：** 同样，使用 top_p（与 temperature 一起称为核采样的技术），可以用来控制模型返回结果的真实性。如果你需要准确和事实的答案，就把参数值调低。如果你想要更多样化的答案，就把参数值调高一些。

一般建议是改变其中一个参数就行，不用两个都调整。

在我们开始一些基础示例之前，请记住最终生成的结果可能会和使用的大语言模型的版本而异。


## 基本概念

### 基础提示词

您可以通过简单的提示词（Prompts）获得大量结果，但结果的质量与您提供的信息数量和完善度有关。一个提示词可以包含您传递到模型的_指令_或_问题_等信息，也可以包含其他详细信息，如_上下文_、_输入_或_示例_等。您可以通过这些元素来更好地指导模型，并因此获得更好的结果。

看下面一个简单的示例：

_提示词_

```
The sky is
```

_输出结果_

```
blue

The sky is blue on a clear day. On a cloudy day, the sky may be gray or white.
```

如以上示例，语言模型能够基于我们给出的上下文内容 `"The sky is" 完成续写。 而输出的结果可能是出人意料的，或远高于我们的任务要求。 

基于以上示例，如果想要实现更具体的目标，我们还必须提供更多的背景信息或说明信息。

可以按如下示例试着完善一下：

_提示词_

```
完善以下句子:

The sky is
```

_输出结果_

```
so  beautiful today.
```

结果是不是要好一些了？本例中，我们告知模型去完善句子，因此输出的结果和我们最初的输入是完全符合的。**提示工程**（Prompt Engineering）就是探讨如何设计出最佳提示词，用于指导语言模型帮助我们高效完成某项任务。

以上示例基本说明了现阶段的大语言模型能够发挥的功能作用。它们可以用于执行各种高级任务，如文本概括、数学推理、代码生成等。

### 提示词格式

前文中我们还是采取的比较简单的提示词。 标准提示词应该遵循以下格式：

```
<问题>?
```

或 

```
<指令>
```

这种可以被格式化为标准的问答格式，如：

```
Q: <问题>?
A: 
```

以上的提示方式，也被称为_零样本提示（zero-shot prompting）_，即用户不提供任务结果相关的示范，直接提示语言模型给出任务相关的回答。某些大型语言模式有能力实现零样本提示，但这也取决于任务的复杂度和已有的知识范围。

基于以上标准范式，目前业界普遍使用的还是更高效的_小样本提示（Few-shot Prompting）_范式，即用户提供少量的提示范例，如任务说明等。小样本提示一般遵循以下格式：

```
<问题>?
<答案>

<问题>?
<答案>

<问题>?
<答案>

<问题>?

```

而问答模式即如下：

```
Q: <问题>?
A: <答案>

Q: <问题>?
A: <答案>

Q: <问题>?
A: <答案>

Q: <问题>?
A:
```

注意，使用问答模式并不是必须的。你可以根据任务需求调整提示范式。比如，您可以按以下示例执行一个简单的分类任务，并对任务做简单说明：

_提示词_

```
This is awesome! // Positive
This is bad! // Negative
Wow that movie was rad! // Positive
What a horrible show! //
```

_输出结果_

```
Negative
```

语言模型可以基于一些说明了解和学习某些任务，而小样本提示正好可以赋能上下文学习能力。

## 提示词要素

如果您接触过大量提示工程相关的示例和应用，您会注意到提示词是由一些要素组成的。

提示词可以包含以下任意要素：

**指令**：想要模型执行的特定任务或指令。

**上下文**：包含外部信息或额外的上下文信息，引导语言模型更好地响应。

**输入数据**：用户输入的内容或问题。

**输出指示**：指定输出的类型或格式。

注意，提示词所需的格式取决于您想要语言模型完成的任务类型，并非所有以上要素都是必须的。我们会在后续的指南中提供更多更具体的示例。

## 设计提示的通用技巧

以下是设计提示时需要记住的一些技巧：

### 从简单开始
在设计提示时，需要记住这是一个迭代的过程，需要大量的实验来获得最佳结果。使用像OpenAI或Cohere这样的简单平台是一个很好的起点。

您可以从简单的提示开始，随着您的目标是获得更好的结果，不断添加更多的元素和上下文。在此过程中对您的提示进行版本控制是至关重要的。当您阅读本指南时，您会看到许多例子，其中具体性、简洁性和简明性通常会给您带来更好的结果。

当您有一个涉及许多不同子任务的大任务时，您可以尝试将任务分解为更简单的子任务，并随着获得更好的结果而不断构建。这避免了在提示设计过程中一开始就添加过多的复杂性。

### 指令
您可以使用命令来指示模型执行各种简单任务，例如“写入”、“分类”、“总结”、“翻译”、“排序”等，从而为各种简单任务设计有效的提示。

请记住，您还需要进行大量的实验，以查看哪种方法最有效。尝试使用不同的关键字、上下文和数据尝试不同的指令，看看哪种方法最适合您的特定用例和任务。通常情况下，上下文与您要执行的任务越具体和相关，效果越好。我们将在即将推出的指南中介绍采样和添加更多上下文的重要性。

其他人建议将指令放在提示的开头。建议使用一些清晰的分隔符，如“###”，来分隔指令和上下文。

例如：

*提示：*
```
### 指令 ###
将以下文本翻译成西班牙语：

文本：“hello！”
```

*输出：*
```
¡Hola!
```

### 具体性
对您希望模型执行的指令和任务非常具体。提示越具体和详细，结果就越好。当您有所期望的结果或生成样式时，这一点尤为重要。没有特定的令牌或关键字会导致更好的结果。更重要的是具有良好的格式和描述性提示。实际上，在提示中提供示例非常有效，可以以特定格式获得所需的输出。

在设计提示时，您还应考虑提示的长度，因为提示的长度有限制。考虑到您应该具体和详细的程度是需要考虑的。包含太多不必要的细节并不一定是一个好方法。这些细节应该是相关的，并有助于完成手头的任务。这是您需要进行大量实验的事情。我们鼓励大量实验和迭代，以优化您的应用程序的提示。

例如，让我们尝试从一段文本中提取特定信息的简单提示。

*提示：*
```
提取以下文本中的地名。

所需格式：
地点：<逗号分隔的公司名称列表>

输入：“虽然这些发展对研究人员来说是令人鼓舞的，但仍有许多谜团。里斯本未知的香帕利莫德中心的神经免疫学家Henrique Veiga-Fernandes说：“我们经常在大脑和我们在周围看到的效果之间有一个黑匣子。”“如果我们想在治疗背景下使用它，我们实际上需要了解机制。””
```

*输出：*
```
地点：里斯本，香帕利莫德中心
```

输入文本来自[这篇Nature文章](https://www.nature.com/articles/d41586-023-00509-z)。

### 避免不精确
在上面关于详细和格式改进的提示中，很容易陷入想要过于聪明的提示陷阱，从而可能创建不精确的描述。通常最好是具体和直接。这里的类比非常类似于有效的沟通——越直接，信息传递就越有效。

例如，您可能有兴趣了解提示工程的概念。您可以尝试这样做：

```
解释提示工程的概念。保持解释简短，只有几句话，不要过于描述。
```

从上面的提示中不清楚要使用多少句话和什么样的风格。您可能仍然可以通过上面的提示获得良好的响应，但更好的提示是非常具体、简洁和直接的。例如：

```
使用2-3句话向高中学生解释提示工程的概念。
```

### 做还是不做？
设计提示时的另一个常见技巧是避免说不要做什么，而是说要做什么。这鼓励更具体化，并关注导致模型产生良好响应的细节。

以下是一个电影推荐聊天机器人的示例，因为我写的指令——关注于不要做什么，而失败了。

*提示：*
```
以下是向客户推荐电影的代理程序。不要询问兴趣。不要询问个人信息。

客户：请根据我的兴趣推荐电影。
代理：
```

*输出：*
```
当然，我可以根据您的兴趣推荐电影。您想看什么类型的电影？您喜欢动作片、喜剧片、爱情片还是其他类型的电影？
```

以下是更好的提示：

*提示：*
```
以下是向客户推荐电影的代理程序。代理负责从全球热门电影中推荐电影。它应该避免询问用户的偏好并避免询问个人信息。如果代理没有电影推荐，它应该回答“抱歉，今天找不到电影推荐。”。
```顾客：请根据我的兴趣推荐一部电影。
客服：

```
*输出：*
```
抱歉，我没有关于您兴趣的任何信息。不过，这是目前全球热门的电影列表：[电影列表]。希望您能找到喜欢的电影！
```

上述示例中的一些内容摘自["Best practices for prompt engineering with OpenAI API" article.](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)

## 提示词示例

在上一节中，我们介绍并给出了如何赋能大语言模型的基本示例。

在本节中，我们会提供更多示例，介绍如何使用提示词来完成不同的任务，并介绍其中涉及的重要概念。通常，学习概念的最佳方法是通过示例进行学习。下面，我们将通过示例介绍说明如何使用精细的提示词来执行不同类型的任务。

主题：

-   [文本概括](#文本概括)
-   [信息提取](#信息提取)
-   [问答](#问答)
-   [文本分类](#文本分类)
-   [对话](#对话)
-   [代码生成](#代码生成)
-   [推理](#推理)

* * *

### 文本概括

自然语言生成的标准任务之一是文本概括。文本概括可能涉及到不同的风格和领域。事实上，语言模型最前景的应用场景之一就是能够快速概括出易于理解的文章大意和相关概念。 我们可以使用提示词尝试一个简单的概括任务。

假设我想了解抗生素的相关信息，我可以给出这样的提示：

_提示词_

```
Explain antibiotics

A:
```

_输出结果_

```
Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.
```

在问答形式中，“A:” 是一种明确的提示格式。 在这个示例中，我用它去提示模型，我想要该概念的进一步解释。 在这个例子中，我们可能还不清楚使用它是否有用，我们会在之后的示例中探讨这一点。 现在假设我们感觉模型给了太多的信息，想要进一步提炼它。 我们可以指导模型帮我们用一句话总结相关内容：

_提示词_

```
Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body’s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.

Explain the above in one sentence: // 用一句话解释上面的信息：
```

_输出结果_

```
Antibiotics are medications used to treat bacterial infections by either killing the bacteria or stopping them from reproducing, but they are not effective against viruses and overuse can lead to antibiotic resistance.
```

本示例是模型在没有过多关注上文输出内容的准确性的情况下，尝试用一个句子来总结段落内容。 关于上文准确性，我们可以通过指令或说明进一步改善它，这一点我们会在后续指南中进行探讨。 读到这里，您可以暂时停住并进行实验，看看是否能获得更好的结果。

* * *

### 信息提取

语言模型通过训练不仅可以用于执行自然语言生成相关任务，还可以用于执行文本分类和其他一系列自然语言处理 (NLP) 任务。 

使用以下示例提示词从指定段落中提取信息：

_提示词_

```
Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.

Mention the large language model based product mentioned in the paragraph above: // 指出上文中提到的大语言模型：
```

_输出结果_

```
The large language model based product mentioned in the paragraph above is ChatGPT.
```

我们可以通过许多方式改进以上结果，但当前方式已经非常有用。

现在应该很明显，您可以通过简单地指示语言模型去执行不同的任务。 AI 研发人员也利用这种能力来构建强大的产品和体验。

Paragraph source: [ChatGPT: five priorities for research](https://www.nature.com/articles/d41586-023-00288-7) 

* * *

### 问答

提高模型响应精确度的最佳方法之一是改进提示词的格式。 如前所述，提示词可以通过指令、上下文、输入和输出指示以改进响应结果。 虽然这些要素不是必需的，但如果您的指示越明确，响应的结果就会越好。 以下示例可以说明结构化提示词的重要性。

_提示词_

```
Answer the question based on the context below. Keep the answer short and concise. Respond "Unsure about answer" if not sure about the answer. // 基于以下语境回答问题。如果不知道答案的话，请回答“不确定答案”。

Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.

Question: What was OKT3 originally sourced from?

Answer:
```

_输出结果_

```
Mice.
```

语境参考至 [Nature](https://www.nature.com/articles/d41586-023-00400-x)。

* * *

### 文本分类

目前，我们已经会使用简单的指令来执行任务。 作为提示工程师，您需要提供更好的指令。 此外， 您也会发现，对于更负责的使用场景，仅提供指令是远远不够的。 所以，您需要思考如何在提示词中包含相关语境和其他不同要素。 同样，你还可以提供其他的信息，如`输入数据`和`示例`。 

可以通过以下示例体验文本分类：

_提示词_

```
Classify the text into neutral, negative or positive. // 将文本按中立、负面或正面进行分类

Text: I think the food was okay. 
Sentiment:
```

_输出结果_

```
Neutral
```

我们给出了对文本进行分类的指令，语言模型做出了正确响应，判断文本类型为 `'Neutral'`。 如果我们想要语言模型以指定格式做出响应， 比如，我们想要它返回 `neutral` 而不是 `Neutral`， 那我们要如何做呢？ 我们有多种方法可以实现这一点。 此例中，我们主要是关注绝对特性，因此，我们提示词中包含的信息越多，响应结果就会越好。 我们可以使用以下示例来校正响应结果：  

_提示词_

```
Classify the text into neutral, negative or positive. 

Text: I think the vacation is okay.
Sentiment: neutral 

Text: I think the food was okay. 
Sentiment:
```

_输出结果_

```
neutral
```

完美！ 这次模型返回了 `neutral`，这正是我们想要的特定标签。 提示词中的示例使得模型可以给出更具体的响应。 有时给出具体的指令十分重要，可以通过以下示例感受这一点：

_提示词_

```
Classify the text into nutral, negative or positive. 

Text: I think the vacation is okay.
Sentiment:
```

_输出结果_

```
Neutral
```

这时候你知道给出具体指令的重要性了吧？

* * *

### 对话

你可以通过提示工程进行更有趣的实验，比如指导大语言模型系统如何表现，指定它的行为意图和身份。 如果你正在构建客服聊天机器人之类的对话系统时，这项功能尤其有用。

比如，可以通过以下示例创建一个对话系统，该系统能够基于问题给出技术性和科学的回答。 你可以关注我们是如何通过指令明确地告诉模型应该如何表现。 这种应用场景有时也被称为 _角色提示（Role Prompting）_。

_提示词_

```
The following is a conversation with an AI research assistant. The assistant tone is technical and scientific. // 以下是与 AI 助理的对话，语气应该专业、技术性强。

Human: Hello, who are you?
AI: Greeting! I am an AI research assistant. How can I help you today?
Human: Can you tell me about the creation of blackholes?
AI:
```

_输出结果_

```
Sure! Black holes are regions of spacetime where the gravitational force is so strong that nothing, not even light, can escape from it. They are created when a very massive star dies and its core collapses in on itself, forming a singularity of infinite density. The intense gravity of the singularity pulls in all the matter and radiation around it, creating the black hole.
```

我们的 AI 助理给出的回答非常技术对吧？ 下面，我们让它给出更易于理解的答案。 

_提示词_

```
The following is a conversation with an AI research assistant. The assistant answers should be easy to understand even by primary school students. // 以下是与 AI 助理的对话。请给出易于理解的答案，最好是小学生都能看懂的那种。

Human: Hello, who are you?
AI: Greeting! I am an AI research assistant. How can I help you today?
Human: Can you tell me about the creation of black holes?
AI: 
```

_输出结果_

```
Sure! Black holes are created when a very massive star runs out of fuel and collapses in on itself. The gravity of the star is so strong that nothing, not even light, can escape its pull. This creates a point in space-time with an intense gravitational force called a black hole.
```

我想我们应该取得了一些进展， 你也可以继续改进它。 如果你再添加更多的示例，可能会得到更好的结果。 

* * *

### 代码生成

大语言模型另外一个有效的应用场景是代码生成。 在此方面，Copilot 就是一个很好的示例。 你可以通过一些有效的提示词执行代码生成任务。 让我们来看一下下面的例子。

我们先用它写个简单的用户欢迎程序：

_提示词_

```
/*
询问用户的姓名并说“ Hello”
*/
```

_输出结果_

```
let name = prompt("What is your name?");
console.log(`Hello, ${name}!`);
```

你看，我们甚至都不需要指定要使用的编程语言。

来，我们再稍微升级一下。 下面的例子会向你展示提示词会让大语言模型变得多么强大。

_提示词_

```
"""
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Create a MySQL query for all students in the Computer Science Department
"""
```

_输出结果_

```
SELECT StudentId, StudentName 
FROM students 
WHERE DepartmentId IN (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science');
```

挺厉害的嘛。 本例中，我们提供了有关数据库架构并要求它生成有效的 MySQL 查询。 

* * *

### 推理

目前对于大语言模型来说，推理任务算是最具有挑战性的了。 推理任务最让人兴奋的地方就是可以促使各种复杂的应用程序从大语言模型中诞生。

目前，涉及数学能力的推理任务已经有了一些改进。 对于当前的大型语言模型来说，执行推理任务可能会有一些难度，因此就需要更高级的提示词工程技术。 我们会在后面的指南中介绍这些高级技术。 现在，我们将介绍几个基本示例来展示算术功能。

_提示词_

```
What is 9,000 * 9,000?
```

_输出结果_

```
81,000,000
```

来，我们加大难度： 

_提示词_

```
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 

A: 
```

_输出结果_

```
No, the odd numbers in this group add up to an odd number: 119.
```

这不对！ 我们试着用提示词去改进它：

_提示词_

```
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 

Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even. 
```

_输出结果_

```
Odd numbers: 15, 5, 13, 7, 1
Sum: 41 
41 is an odd number.
```

好多了吧？ 顺便说一句，我试过几次，有时还是会失败。 如果你可以用示例给模型说明一下，可能会获得更准确的结果。

我们后面还会在本章节中介绍更多常见应用示例。

在后面的章节，我们将介绍更高级的提示工程概念和技术，以完成更困难任务。
